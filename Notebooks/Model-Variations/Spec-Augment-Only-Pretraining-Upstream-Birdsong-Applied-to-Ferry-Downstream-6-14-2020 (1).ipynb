{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spec Augment Only with Ferry Downstream Task\n",
    "## Wav Temporal Order Self-Supervised Learning from Birdsong Applied to Ferry Motor Classification.\n",
    "Self-Supervised Model, Extracted Weights, and Load into Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last Updated Date June 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "plt.style.use('seaborn-white')\n",
    "from IPython.display import Markdown, display\n",
    "from IPython.display import SVG\n",
    "import numpy as np\n",
    "from time import time\n",
    "np.random.seed(10)\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pyAudioAnalysis\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "from pyAudioAnalysis import ShortTermFeatures, MidTermFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import resampy\n",
    "import librosa\n",
    "from librosa import cqt\n",
    "\n",
    "import scipy.io.wavfile as wavfile \n",
    "import librosa\n",
    "import plotly\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "from scipy.signal import medfilt as mf\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "import scipy.io.wavfile as wavfile\n",
    "np.set_printoptions(suppress=True)\n",
    "import argparse\n",
    "from pydub import AudioSegment\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds_home = os.path.join('/home/pattyry/birds/')\n",
    "#cwd_audio = os.path.join(\"..\",\"..\",\"birds\")\n",
    "os.chdir(birds_home)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cqt-sequences_train\n"
     ]
    }
   ],
   "source": [
    "cqt_train = os.path.join('./cqt-sequences_train')\n",
    "cqt_test = os.path.join('./cqt-sequences_test')\n",
    "spec_cqt_train = os.path.join('./spec-aug-sequences_train')\n",
    "spec_cqt_test = os.path.join('./spec-aug-sequences_test')\n",
    "new_train_test = os.path.join('./new-train-test')\n",
    "print(cqt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "img_rows, img_cols = 70, 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds/cqt-sequences_train'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "os.chdir(cqt_train)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 7840)\n",
      "(763, 7840)\n",
      "(763, 7840)\n",
      "(763, 7840)\n",
      "(763, 2)\n"
     ]
    }
   ],
   "source": [
    "train_x_cqt_1=pd.read_csv('a_train_cqt.csv', sep=',',header=None)\n",
    "print(train_x_cqt_1.shape)\n",
    "train_x_cqt_1 = np.asarray(train_x_cqt_1)\n",
    "\n",
    "train_x_cqt_2=pd.read_csv('b_train_cqt.csv', sep=',',header=None)\n",
    "print(train_x_cqt_2.shape)\n",
    "train_x_cqt_2 = np.asarray(train_x_cqt_2)\n",
    "\n",
    "train_x_cqt_3=pd.read_csv('c_train_cqt.csv', sep=',',header=None)\n",
    "print(train_x_cqt_3.shape)\n",
    "train_x_cqt_3 = np.asarray(train_x_cqt_3)\n",
    "\n",
    "train_x_cqt_4=pd.read_csv('d_train_cqt.csv', sep=',',header=None)\n",
    "print(train_x_cqt_4.shape)\n",
    "train_x_cqt_4 = np.asarray(train_x_cqt_4)\n",
    "\n",
    "\n",
    "train_y_cqt=pd.read_csv('labels_train_cqt.csv', sep=',',header=None)\n",
    "print(train_y_cqt.shape)\n",
    "train_y_cqt = np.asarray(train_y_cqt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds/cqt-sequences_test'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "os.chdir(cqt_test)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 7840)\n",
      "(489, 7840)\n",
      "(489, 7840)\n",
      "(489, 7840)\n",
      "(489, 2)\n"
     ]
    }
   ],
   "source": [
    "test_x_cqt_1=pd.read_csv('a_test_cqt.csv', sep=',',header=None)\n",
    "print(test_x_cqt_1.shape)\n",
    "test_x_cqt_1 = np.asarray(test_x_cqt_1)\n",
    "\n",
    "test_x_cqt_2=pd.read_csv('b_test_cqt.csv', sep=',',header=None)\n",
    "print(test_x_cqt_2.shape)\n",
    "test_x_cqt_2 = np.asarray(test_x_cqt_2)\n",
    "\n",
    "test_x_cqt_3=pd.read_csv('c_test_cqt.csv', sep=',',header=None)\n",
    "print(test_x_cqt_3.shape)\n",
    "test_x_cqt_3 = np.asarray(test_x_cqt_3)\n",
    "\n",
    "test_x_cqt_4=pd.read_csv('d_test_cqt.csv', sep=',',header=None)\n",
    "print(test_x_cqt_4.shape)\n",
    "test_x_cqt_4 = np.asarray(test_x_cqt_4)\n",
    "\n",
    "test_y_cqt=pd.read_csv('labels_test_cqt.csv', sep=',',header=None)\n",
    "print(test_y_cqt.shape)\n",
    "test_y_cqt = np.asarray(test_y_cqt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b_train.csv',\n",
       " 'labels_test.csv',\n",
       " 'd_train.csv',\n",
       " 'a_train.csv',\n",
       " 'c_train.csv',\n",
       " 'labels_train.csv']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "os.chdir(spec_cqt_train)\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 7840)\n",
      "(763, 7840)\n",
      "(763, 7840)\n",
      "(763, 7840)\n",
      "(763, 2)\n"
     ]
    }
   ],
   "source": [
    "train_x_spec_1=pd.read_csv('a_train.csv', sep=',',header=None)\n",
    "print(train_x_spec_1.shape)\n",
    "train_x_spec_1 = np.asarray(train_x_spec_1)\n",
    "\n",
    "train_x_spec_2=pd.read_csv('b_train.csv', sep=',',header=None)\n",
    "print(train_x_spec_2.shape)\n",
    "train_x_spec_2 = np.asarray(train_x_spec_2)\n",
    "\n",
    "train_x_spec_3=pd.read_csv('c_train.csv', sep=',',header=None)\n",
    "print(train_x_spec_3.shape)\n",
    "train_x_spec_3 = np.asarray(train_x_spec_3)\n",
    "\n",
    "train_x_spec_4=pd.read_csv('d_train.csv', sep=',',header=None)\n",
    "print(train_x_spec_4.shape)\n",
    "train_x_spec_4 = np.asarray(train_x_spec_4)\n",
    "\n",
    "train_y_spec=pd.read_csv('labels_train.csv', sep=',',header=None)\n",
    "print(train_y_spec.shape)\n",
    "train_y_spec = np.asarray(train_y_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels_test.csv', 'b_test.csv', 'a_test.csv', 'd_test.csv', 'c_test.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "os.chdir(spec_cqt_test)\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(489, 7840)\n",
      "(489, 7840)\n",
      "(489, 7840)\n",
      "(489, 7840)\n",
      "(489, 2)\n"
     ]
    }
   ],
   "source": [
    "test_x_spec_1=pd.read_csv('a_test.csv', sep=',',header=None)\n",
    "print(test_x_spec_1.shape)\n",
    "test_x_spec_1 = np.asarray(test_x_spec_1)\n",
    "\n",
    "test_x_spec_2=pd.read_csv('b_test.csv', sep=',',header=None)\n",
    "print(test_x_spec_2.shape)\n",
    "test_x_spec_2 = np.asarray(test_x_spec_2)\n",
    "\n",
    "test_x_spec_3=pd.read_csv('c_test.csv', sep=',',header=None)\n",
    "print(test_x_spec_3.shape)\n",
    "test_x_spec_3 = np.asarray(test_x_spec_3)\n",
    "\n",
    "test_x_spec_4=pd.read_csv('d_test.csv', sep=',',header=None)\n",
    "print(test_x_spec_4.shape)\n",
    "test_x_spec_4 = np.asarray(test_x_spec_4)\n",
    "\n",
    "test_y_spec=pd.read_csv('labels_test.csv', sep=',',header=None)\n",
    "print(test_y_spec.shape)\n",
    "test_y_spec = np.asarray(test_y_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c_train_pitch.csv',\n",
       " 'pitch_shifted_train.csv',\n",
       " 'b_train_pitch.csv',\n",
       " 'd_train_pitch.csv',\n",
       " 'a_train_pitch.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "pitch_train = os.path.join(birds_home,'./pitch-shifted_train')\n",
    "os.chdir(pitch_train)\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3052, 7840)\n",
      "(3052, 7840)\n",
      "(3052, 7840)\n",
      "(3052, 7840)\n"
     ]
    }
   ],
   "source": [
    "train_x_pitch_1=pd.read_csv('a_train_pitch.csv', sep=',',header=None)\n",
    "print(train_x_pitch_1.shape)\n",
    "train_x_pitch_1 = np.asarray(train_x_pitch_1)\n",
    "\n",
    "train_x_pitch_2=pd.read_csv('b_train_pitch.csv', sep=',',header=None)\n",
    "print(train_x_pitch_2.shape)\n",
    "train_x_pitch_2 = np.asarray(train_x_pitch_2)\n",
    "\n",
    "train_x_pitch_3=pd.read_csv('c_train_pitch.csv', sep=',',header=None)\n",
    "print(train_x_pitch_3.shape)\n",
    "train_x_pitch_3 = np.asarray(train_x_pitch_3)\n",
    "\n",
    "train_x_pitch_4=pd.read_csv('d_train_pitch.csv', sep=',',header=None)\n",
    "print(train_x_pitch_4.shape)\n",
    "train_x_pitch_4 = np.asarray(train_x_pitch_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d_test_pitch.csv',\n",
       " 'pitch_shifted_test.csv',\n",
       " 'c_test_pitch.csv',\n",
       " 'b_test_pitch.csv',\n",
       " 'a_test_pitch.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "pitch_test = os.path.join(birds_home,'./pitch-shifted_test')\n",
    "os.chdir(pitch_test)\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1956, 7840)\n",
      "(1956, 7840)\n",
      "(1956, 7840)\n",
      "(1956, 7840)\n"
     ]
    }
   ],
   "source": [
    "test_x_pitch_1=pd.read_csv('a_test_pitch.csv', sep=',',header=None)\n",
    "print(test_x_pitch_1.shape)\n",
    "test_x_pitch_1 = np.asarray(test_x_pitch_1)\n",
    "\n",
    "test_x_pitch_2=pd.read_csv('b_test_pitch.csv', sep=',',header=None)\n",
    "print(test_x_pitch_2.shape)\n",
    "test_x_pitch_2 = np.asarray(test_x_pitch_2)\n",
    "\n",
    "test_x_pitch_3=pd.read_csv('c_test_pitch.csv', sep=',',header=None)\n",
    "print(test_x_pitch_3.shape)\n",
    "test_x_pitch_3 = np.asarray(test_x_pitch_3)\n",
    "\n",
    "test_x_pitch_4=pd.read_csv('d_test_pitch.csv', sep=',',header=None)\n",
    "print(test_x_pitch_4.shape)\n",
    "test_x_pitch_4 = np.asarray(test_x_pitch_4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_train_pitch = len(train_x_pitch_4)\n",
    "samples_test_pitch = len(test_x_pitch_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3052, 1)\n",
      "(1956, 1)\n",
      "(3052, 1)\n",
      "(1956, 1)\n"
     ]
    }
   ],
   "source": [
    "train_labels_positive_pitch = np.full((samples_train_pitch, 1), 1)\n",
    "print(train_labels_positive_pitch.shape)\n",
    "\n",
    "test_labels_positive_pitch = np.full((samples_test_pitch, 1), 1)\n",
    "print(test_labels_positive_pitch.shape)\n",
    "\n",
    "train_labels_negative_pitch = np.full((samples_train_pitch, 1), 0)\n",
    "print(train_labels_negative_pitch.shape)\n",
    "\n",
    "test_labels_negative_pitch = np.full((samples_test_pitch, 1), 0)\n",
    "print(test_labels_negative_pitch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build sets of Samples\n",
    "# Positive Sequence \n",
    "# a, b, c\n",
    "# Negative Sequences:\n",
    "# b, a, d\n",
    "# d, a, b\n",
    "\n",
    "# train_x_cqt_1, train_x_cqt_2, train_x_cqt_3, train_x_cqt_4\n",
    "# test_x_cqt_1, test_x_cqt_2, test_x_cqt_3, test_x_cqt_4\n",
    "# train_y_cqt\n",
    "# test_y_cqt\n",
    "\n",
    "# train_x_spec_1, train_x_spec_2, train_x_spec_3, train_x_spec_4\n",
    "# test_x_spec_1, test_x_spec_2, test_x_spec_3, test_x_spec_4\n",
    "# train_y_spec\n",
    "# test_y_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(763, 1)\n",
      "(489, 1)\n",
      "(763, 1)\n",
      "(489, 1)\n"
     ]
    }
   ],
   "source": [
    "samples_train = len(train_x_cqt_1)\n",
    "samples_test = len(test_x_cqt_1)\n",
    "\n",
    "train_labels_positive = np.full((samples_train, 1), 1)\n",
    "print(train_labels_positive.shape)\n",
    "\n",
    "test_labels_positive = np.full((samples_test, 1), 1)\n",
    "print(test_labels_positive.shape)\n",
    "\n",
    "train_labels_negative = np.full((samples_train, 1), 0)\n",
    "print(train_labels_negative.shape)\n",
    "\n",
    "test_labels_negative = np.full((samples_test, 1), 0)\n",
    "print(test_labels_negative.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_type1_cqt = np.concatenate((train_x_cqt_1, train_x_cqt_2, train_x_cqt_3, train_labels_positive), axis=1)\n",
    "positive_test_type1_cqt = np.concatenate((test_x_cqt_1, test_x_cqt_2, test_x_cqt_3, test_labels_positive), axis=1)\n",
    "\n",
    "negative_train_type2_cqt = np.concatenate((train_x_cqt_2, train_x_cqt_1, train_x_cqt_4, train_labels_negative), axis=1)\n",
    "negative_test_type2_cqt = np.concatenate((test_x_cqt_2, test_x_cqt_1, test_x_cqt_4, test_labels_negative), axis=1)\n",
    "\n",
    "negative_train_type3_cqt = np.concatenate((train_x_cqt_4, train_x_cqt_1, train_x_cqt_2, train_labels_negative), axis=1)\n",
    "negative_test_type3_cqt = np.concatenate((test_x_cqt_4, test_x_cqt_1, test_x_cqt_2, test_labels_negative), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_type1_pitch = np.concatenate((train_x_pitch_1, train_x_pitch_2, train_x_pitch_3, train_labels_positive_pitch), axis=1)\n",
    "positive_test_type1_pitch = np.concatenate((test_x_pitch_1, test_x_pitch_2, test_x_pitch_3, test_labels_positive_pitch), axis=1)\n",
    "\n",
    "negative_train_type2_pitch = np.concatenate((train_x_pitch_2, train_x_pitch_1, train_x_pitch_4, train_labels_negative_pitch), axis=1)\n",
    "negative_test_type2_pitch = np.concatenate((test_x_pitch_2, test_x_pitch_1, test_x_pitch_4, test_labels_negative_pitch), axis=1)\n",
    "\n",
    "negative_train_type3_pitch = np.concatenate((train_x_pitch_4, train_x_pitch_1, train_x_pitch_2, train_labels_negative_pitch), axis=1)\n",
    "negative_test_type3_pitch = np.concatenate((test_x_pitch_4, test_x_pitch_1, test_x_pitch_2, test_labels_negative_pitch), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train_type1_spec = np.concatenate((train_x_spec_1, train_x_spec_2, train_x_spec_3, train_labels_positive), axis=1)\n",
    "positive_test_type1_spec = np.concatenate((test_x_spec_1, test_x_spec_2, test_x_spec_3, test_labels_positive), axis=1)\n",
    "\n",
    "negative_train_type2_spec = np.concatenate((train_x_spec_2, train_x_spec_1, train_x_spec_4, train_labels_negative), axis=1)\n",
    "negative_test_type2_spec = np.concatenate((test_x_spec_2, test_x_spec_1, test_x_spec_4, test_labels_negative), axis=1)\n",
    "\n",
    "negative_train_type3_spec = np.concatenate((train_x_spec_4, train_x_spec_1, train_x_spec_2, train_labels_negative), axis=1)\n",
    "negative_test_type3_spec = np.concatenate((test_x_spec_4, test_x_spec_1, test_x_spec_2, test_labels_negative), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Correct and Incorrect Sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2289, 23521)\n",
      "(1467, 23521)\n"
     ]
    }
   ],
   "source": [
    "train_cqt = np.append(positive_train_type1_cqt, negative_train_type2_cqt, axis=0)\n",
    "train_cqt = np.append(train_cqt, negative_train_type3_cqt, axis=0)\n",
    "print(train_cqt.shape)\n",
    "\n",
    "test_cqt = np.append(positive_test_type1_cqt,negative_test_type2_cqt, axis=0)\n",
    "test_cqt = np.append(test_cqt,negative_test_type3_cqt, axis=0)\n",
    "print(test_cqt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2289, 23521)\n",
      "(1467, 23521)\n"
     ]
    }
   ],
   "source": [
    "train_spec = np.append(positive_train_type1_spec, negative_train_type2_spec, axis=0)\n",
    "train_spec = np.append(train_spec, negative_train_type3_spec, axis=0)\n",
    "print(train_spec.shape)\n",
    "\n",
    "test_spec = np.append(positive_test_type1_spec,negative_test_type2_spec, axis=0)\n",
    "test_spec = np.append(test_spec,negative_test_type3_spec, axis=0)\n",
    "print(test_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9156, 23521)\n",
      "(5868, 23521)\n"
     ]
    }
   ],
   "source": [
    "train_pitch = np.append(positive_train_type1_pitch, negative_train_type2_pitch, axis=0)\n",
    "train_pitch = np.append(train_pitch, negative_train_type3_pitch, axis=0)\n",
    "print(train_pitch.shape)\n",
    "\n",
    "test_pitch = np.append(positive_test_type1_pitch,negative_test_type2_pitch, axis=0)\n",
    "test_pitch = np.append(test_pitch,negative_test_type3_pitch, axis=0)\n",
    "print(test_pitch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self-supervised-temporal-order-2-6-14.hdf5',\n",
       " 'ferry-data',\n",
       " 'birds-notebooks',\n",
       " 'resampled-train',\n",
       " 'pitch-shifted_test',\n",
       " 'spec-aug-sequences_test',\n",
       " 'cqt-sequences_test',\n",
       " 'cqt-sequences_train',\n",
       " 'spec-aug-sequences_train',\n",
       " 'old-train-test',\n",
       " 'spec-and-pitchshift-aug-self-supervised-temporal-order--6-14.hdf5',\n",
       " 'pitch-shifted_train',\n",
       " 'new-train-test',\n",
       " 'resampled-test',\n",
       " 'file-index']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "#os.chdir(spec_cqt_test)\n",
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_cqt)\n",
    "np.random.shuffle(test_cqt)\n",
    "np.random.shuffle(train_spec)\n",
    "np.random.shuffle(test_spec)\n",
    "np.random.shuffle(train_pitch)\n",
    "np.random.shuffle(test_pitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23521\n"
     ]
    }
   ],
   "source": [
    "unrolled_cols = train_cqt.shape[1]\n",
    "print(unrolled_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2289,)\n",
      "(1467,)\n",
      "(2289,)\n",
      "(1467,)\n"
     ]
    }
   ],
   "source": [
    "train_cqt_y = train_cqt[:,-1]\n",
    "test_cqt_y = test_cqt[:,-1]\n",
    "\n",
    "print(train_cqt_y.shape)\n",
    "print(test_cqt_y.shape)\n",
    "\n",
    "train_spec_y = train_spec[:,-1]\n",
    "test_spec_y = test_spec[:,-1]\n",
    "\n",
    "print(train_spec_y.shape)\n",
    "print(test_spec_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23521\n"
     ]
    }
   ],
   "source": [
    "unrolled_cols = train_pitch.shape[1]\n",
    "print(unrolled_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9156,)\n",
      "(5868,)\n",
      "(9156,)\n",
      "(5868,)\n"
     ]
    }
   ],
   "source": [
    "train_pitch_y = train_pitch[:,-1]\n",
    "test_pitch_y = test_pitch[:,-1]\n",
    "\n",
    "print(train_pitch_y.shape)\n",
    "print(test_pitch_y.shape)\n",
    "\n",
    "train_pitch_y = train_pitch[:,-1]\n",
    "test_pitch_y = test_pitch[:,-1]\n",
    "\n",
    "print(train_pitch_y.shape)\n",
    "print(test_pitch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2289, 23520)\n",
      "(2289, 23520)\n",
      "(1467, 23520)\n",
      "(1467, 23520)\n"
     ]
    }
   ],
   "source": [
    "train_cqt_x = train_cqt[:,0:(unrolled_cols-1)]\n",
    "print(train_cqt_x.shape)\n",
    "\n",
    "train_spec_x = train_spec[:,0:(unrolled_cols-1)]\n",
    "print(train_spec_x.shape)\n",
    "\n",
    "test_cqt_x = test_cqt[:,0:(unrolled_cols-1)]\n",
    "print(test_cqt_x.shape)\n",
    "\n",
    "test_spec_x = test_spec[:,0:(unrolled_cols-1)]\n",
    "print(test_spec_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9156, 23520)\n",
      "(5868, 23520)\n"
     ]
    }
   ],
   "source": [
    "train_pitch_x = train_pitch[:,0:(unrolled_cols-1)]\n",
    "print(train_pitch_x.shape)\n",
    "\n",
    "test_pitch_x = test_pitch[:,0:(unrolled_cols-1)]\n",
    "print(test_pitch_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/pattyry/birds/new-train-test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train_pitch_y.csv',\n",
       " 'test_cqt_y.csv',\n",
       " 'train_spec_x.csv',\n",
       " 'test_spec_x.csv',\n",
       " 'test_spec_y.csv',\n",
       " 'test_pitch_y.csv',\n",
       " 'train_cqt_x.csv',\n",
       " 'test_pitch_x.csv',\n",
       " 'train_spec_y.csv',\n",
       " 'train_pitch_x.csv',\n",
       " 'train_cqt_y.csv',\n",
       " 'self-supervised-temporal-order6-4.hdf5',\n",
       " 'test_cqt_x.csv']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "os.chdir(new_train_test)\n",
    "print(os.getcwd())\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('train_cqt_x.csv', train_cqt_x, delimiter=',')  \n",
    "# np.savetxt('train_spec_x.csv', train_spec_x, delimiter=',')  \n",
    "# np.savetxt('train_pitch_x.csv', train_spec_x, delimiter=',')  \n",
    "# np.savetxt('test_cqt_x.csv', test_cqt_x, delimiter=',')  \n",
    "# np.savetxt('test_spec_x.csv', test_spec_x, delimiter=',')  \n",
    "# np.savetxt('test_pitch_x.csv', test_spec_x, delimiter=',')  \n",
    "\n",
    "# np.savetxt('train_spec_y.csv', train_spec_y, delimiter=',')  \n",
    "# np.savetxt('test_spec_y.csv', test_spec_y, delimiter=',')  \n",
    "# np.savetxt('train_cqt_y.csv', train_cqt_y, delimiter=',')  \n",
    "# np.savetxt('test_cqt_y.csv', test_cqt_y, delimiter=',')  \n",
    "# np.savetxt('train_pitch_y.csv', train_cqt_y, delimiter=',')  \n",
    "# np.savetxt('test_pitch_y.csv', test_cqt_y, delimiter=',')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose which augmentations to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4578, 23520)\n",
      "(1467, 23520)\n",
      "(4578,)\n",
      "(1467,)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_x = np.append(train_cqt_x, train_spec_x, axis=0)\n",
    "#train_x = np.append(train_x, train_pitch_x, axis=0)\n",
    "\n",
    "test_x = test_cqt_x \n",
    "\n",
    "train_y = np.append(train_cqt_y, train_spec_y, axis=0)\n",
    "#train_y = np.append(train_y, train_pitch_y, axis=0)\n",
    "\n",
    "test_y = test_cqt_y\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)\n",
    "print(test_y)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4578, 23521)\n",
      "(1467, 23521)\n"
     ]
    }
   ],
   "source": [
    "train_labelled = np.asarray(pd.concat([pd.DataFrame(train_x), pd.DataFrame(train_y)], axis=1))\n",
    "test_labelled = np.asarray(pd.concat([pd.DataFrame(test_x), pd.DataFrame(test_y)], axis=1))\n",
    "print(train_labelled.shape)\n",
    "print(test_labelled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_labelled)\n",
    "np.random.shuffle(test_labelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1467, 23521)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4578, 23521)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4578"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_samples = np.shape(train_labelled)[0]\n",
    "num_train_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1467"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_samples = np.shape(test_labelled)[0]\n",
    "num_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4578,)\n",
      "(1467,)\n",
      "[0. 1. 1. ... 0. 1. 0.]\n",
      "[0. 0. 0. ... 0. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "train_y_shuffled = np.asarray(train_labelled)[:,-1]\n",
    "print(train_y_shuffled.shape)\n",
    "\n",
    "test_y_shuffled = np.asarray(test_labelled)[:,-1]\n",
    "print(test_y_shuffled.shape)\n",
    "\n",
    "train_y_ =  np.array(train_y_shuffled).reshape(num_train_samples)\n",
    "test_y_ =  np.array(test_y_shuffled).reshape(num_test_samples)\n",
    "print(train_y_)\n",
    "print(test_y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4578, 23520)\n",
      "(1467, 23520)\n"
     ]
    }
   ],
   "source": [
    "train_x_shuffled = np.asarray(train_labelled)[:,0:(unrolled_cols-1)]\n",
    "print(train_x_shuffled.shape)\n",
    "\n",
    "test_x_shuffled = np.asarray(test_labelled)[:,0:(unrolled_cols-1)]\n",
    "print(test_x_shuffled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_shuffled, train_y_shuffled\n",
    "# test_x_shuffled, test_y_shuffled\n",
    "\n",
    "#7840"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Data for Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4578, 7840)\n"
     ]
    }
   ],
   "source": [
    "# Split 'x' series back into sequences\n",
    "train_x_1 = train_x_shuffled[:,0:7840]\n",
    "train_x_2 = train_x_shuffled[:,7840:15680]\n",
    "train_x_3 = train_x_shuffled[:,15680:]\n",
    "print(train_x_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_1 = train_x_shuffled[:,0:7840]\n",
    "train_x_2 = train_x_shuffled[:,7840:15680]\n",
    "train_x_3 = train_x_shuffled[:,15680:]\n",
    "\n",
    "test_x_1 = test_x_shuffled[:,0:7840]\n",
    "test_x_2 = test_x_shuffled[:,7840:15680]\n",
    "test_x_3 = test_x_shuffled[:,15680:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467\n",
      "4578\n",
      "70\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "#Define Single input shape\n",
    "num_test_samples = test_x_shuffled.shape[0]\n",
    "num_train_samples = train_x_shuffled.shape[0]\n",
    "num_timesteps = 70\n",
    "num_features = 112\n",
    "print(num_test_samples)\n",
    "print(num_train_samples)\n",
    "print(num_timesteps)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4578, 70, 112, 1)\n",
      "(1467, 70, 112, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x_1 = np.array(train_x_1).reshape(num_train_samples, num_timesteps, num_features, 1)\n",
    "train_x_2 = np.array(train_x_2).reshape(num_train_samples, num_timesteps, num_features, 1)\n",
    "train_x_3 = np.array(train_x_3).reshape(num_train_samples, num_timesteps, num_features, 1)\n",
    "print(train_x_1.shape)\n",
    "\n",
    "test_x_1 = np.array(test_x_1).reshape(num_test_samples, num_timesteps, num_features, 1)\n",
    "test_x_2 = np.array(test_x_2).reshape(num_test_samples, num_timesteps, num_features, 1)\n",
    "test_x_3 = np.array(test_x_3).reshape(num_test_samples, num_timesteps, num_features, 1)\n",
    "print(test_x_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1467, 70, 112, 1)\n",
      "(4578, 70, 112, 1)\n",
      "(1467, 70, 112, 1)\n",
      "(4578, 70, 112, 1)\n",
      "(1467, 70, 112, 1)\n",
      "(4578, 70, 112, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_x_1.shape)\n",
    "print(train_x_1.shape)\n",
    "      \n",
    "print(test_x_2.shape)\n",
    "print(train_x_2.shape)\n",
    "\n",
    "print(test_x_3.shape)\n",
    "print(train_x_3.shape)\n",
    "\n",
    "train_x_1 = np.float32(train_x_1)\n",
    "test_x_1 = np.float32(test_x_1)\n",
    "\n",
    "train_x_2 = np.float32(train_x_2)\n",
    "test_x_2 = np.float32(test_x_2)\n",
    "\n",
    "train_x_3 = np.float32(train_x_3)\n",
    "test_x_3 = np.float32(test_x_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 112, 1)\n",
      "(4578, 70, 112, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqt_input_shape = train_x_1[0].shape\n",
    "print(cqt_input_shape)\n",
    "print(train_x_1.shape)\n",
    "type(train_x_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import pywt\n",
    "from matplotlib.image import imread\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path\n",
    "import pywt\n",
    "#import soundfile\n",
    "import random\n",
    "import pickle\n",
    "from glob import iglob\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pprint\n",
    "random.seed(42)\n",
    "import librosa\n",
    "import scipy.signal\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten, Conv2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import initializers \n",
    "from tensorflow.keras import regularizers \n",
    "from tensorflow.keras import constraints \n",
    "from tensorflow.keras.layers import Activation\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D,concatenate\n",
    "from tensorflow.keras.layers import MaxPooling3D, Flatten, Conv3D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LeakyReLU,PReLU\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import load_model\n",
    "# def my_init(shape,  dtype=None):\n",
    "#      vals=((float(shape[0], float(shape[1]))) * math.sqrt(2./float(shape[1])))\n",
    "#      return K.random_normal(vals, dtype=dtype)    \n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "#Before prediction\n",
    "K.clear_session()\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# # #session = InteractiveSession.close()\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[3052 1526]\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "len(train_y)\n",
    "unique, counts = np.unique(train_y_, return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If wanted, add class weighting\n",
    "total_len = len(train_y)\n",
    "class_weight = {0: total_len/len([x for x in train_y_==0 if x]),\n",
    "                1: total_len/len([x for x in train_y_==1 if x])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    with tf.device(\"GPU:1\"):\n",
    "        nclass = 2\n",
    "        initializer1 = tf.keras.initializers.RandomNormal\n",
    "        initializer2 = tf.keras.initializers.Zeros()\n",
    "        initializer3 = tf.keras.initializers.glorot_uniform(seed=None)\n",
    "        initializer4 = tf.keras.initializers.lecun_normal(seed=None)\n",
    "        initializer5 = tf.keras.initializers.TruncatedNormal(mean=0., stddev=1.)\n",
    "\n",
    "        inp = Input(shape=cqt_input_shape)\n",
    "        img_1 = LeakyReLU(alpha=0.3)(inp)\n",
    "        img_1 = Conv2D(128, kernel_size=(7,7), \n",
    "                       kernel_initializer=initializer4,  kernel_regularizer = regularizers.l2(0.001),         \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_1)\n",
    "        img_1 = Dropout(0.3)(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = MaxPooling2D()(img_1)\n",
    "        img_1 = Conv2D(128, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, kernel_regularizer = regularizers.l2(0.001),            \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = MaxPooling2D()(img_1)\n",
    "        img_1 = Dropout(0.3)(img_1)\n",
    "        img_1 = Conv2D(256, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, kernel_regularizer = regularizers.l2(0.001),            \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.5)(img_1)   \n",
    "        img_1 = Flatten()(img_1)      \n",
    "        img_1 = Dense(512, kernel_initializer=initializer4,  kernel_regularizer = regularizers.l2(0.001))(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.5)(img_1)   \n",
    "        \n",
    "\n",
    "        inp2 = Input(shape=cqt_input_shape)\n",
    "        img_2 = LeakyReLU(alpha=0.2)(inp2)\n",
    "        img_2 = Conv2D(128, kernel_size=(7,7), \n",
    "                       kernel_initializer=initializer4,  kernel_regularizer = regularizers.l2(0.001),         \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros())(img_2)\n",
    "        img_2 = Dropout(0.3)(img_2)\n",
    "        img_2 = LeakyReLU(alpha=0.2)(img_2)\n",
    "        img_2 = MaxPooling2D()(img_2)\n",
    "        img_2 = Conv2D(128, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, kernel_regularizer = regularizers.l2(0.001),            \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_2)\n",
    "        img_2 = LeakyReLU(alpha=0.2)(img_2)\n",
    "        img_2 = MaxPooling2D()(img_2)\n",
    "        img_2 = Dropout(0.3)(img_2)\n",
    "\n",
    "        img_2 = Conv2D(256, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, kernel_regularizer = regularizers.l2(0.001),            \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_2)\n",
    "        img_2 = LeakyReLU(alpha=0.2)(img_2)\n",
    "        img_2 = Dropout(0.5)(img_2)\n",
    "        img_2 = Flatten()(img_2)   \n",
    "\n",
    "        img_2 = Dense(512, kernel_initializer=initializer4,  kernel_regularizer = regularizers.l2(0.001))(img_2)\n",
    "        img_2 = LeakyReLU(alpha=0.2)(img_2)\n",
    "        img_2 = Dropout(0.5)(img_2)\n",
    "\n",
    "\n",
    "        inp3 = Input(shape=cqt_input_shape)\n",
    "        img_3 = LeakyReLU(alpha=0.2)(inp3)\n",
    "        img_3 = Conv2D(128, kernel_size=(7,7), \n",
    "                       kernel_initializer=initializer4,  kernel_regularizer = regularizers.l2(0.001),         \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_3)\n",
    "        img_3 = Dropout(0.3)(img_3)\n",
    "        img_3 = LeakyReLU(alpha=0.2)(img_3)\n",
    "        img_3 = MaxPooling2D()(img_3)\n",
    "        img_3 = Conv2D(128, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, kernel_regularizer = regularizers.l2(0.001),            \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_3)\n",
    "        img_3 = LeakyReLU(alpha=0.2)(img_3)\n",
    "        img_3 = MaxPooling2D()(img_3)\n",
    "        img_3 = Dropout(0.3)(img_3)\n",
    "\n",
    "        img_3 = Conv2D(256, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, kernel_regularizer = regularizers.l2(0.001),            \n",
    "                       use_bias=True, bias_initializer=initializers.Zeros(),padding=\"valid\")(img_3)\n",
    "        img_3 = LeakyReLU(alpha=0.2)(img_3)\n",
    "        img_3 = Dropout(0.5)(img_3)\n",
    "        img_3 = Flatten()(img_3)   \n",
    "\n",
    "        img_3 = Dense(512, kernel_initializer=initializer4,   kernel_regularizer = regularizers.l2(0.001))(img_3)\n",
    "        img_3 = LeakyReLU(alpha=0.2)(img_3)\n",
    "        img_3 = Dropout(0.5)(img_3)\n",
    "\n",
    "\n",
    "        concat_layer = keras.layers.concatenate([img_1, img_2, img_3])\n",
    "        concat_dense = LeakyReLU(alpha=0.2)(concat_layer)\n",
    "        concat_dense = Dense(256, kernel_initializer=initializer4,  kernel_regularizer = regularizers.l2(0.001),\n",
    "                             bias_initializer=initializers.Zeros(),use_bias=True)(concat_dense)\n",
    "        concat_dense = Dropout(0.5)(concat_dense)\n",
    "        concat_dense = Dense(16, kernel_regularizer = regularizers.l2(0.1))(concat_dense)\n",
    "        concat_dense = Dropout(0.5)(concat_dense)   \n",
    "\n",
    "        output_layer = Dense(2,activation=activations.sigmoid)(concat_dense)\n",
    "        model = models.Model(inputs=[inp, inp2, inp3], outputs=[output_layer])\n",
    "        opt = optimizers.Adam(lr=0.0009, beta_1=0.9, beta_2=0.999, epsilon=1e-5, decay=.03, amsgrad=False)\n",
    "        model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0614 13:39:27.958874 140178680968960 deprecation.py:506] From /opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0614 13:39:27.960779 140178680968960 deprecation.py:506] From /opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:94: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0614 13:39:30.184850 140178680968960 deprecation.py:323] From /opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 70, 112, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 70, 112, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 70, 112, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 70, 112, 1)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 70, 112, 1)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 70, 112, 1)   0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 106, 128) 6400        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 106, 128) 6400        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 106, 128) 6400        leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 106, 128) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 106, 128) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 106, 128) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 64, 106, 128) 0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64, 106, 128) 0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 64, 106, 128) 0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 32, 53, 128)  0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 53, 128)  0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 53, 128)  0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 30, 51, 128)  147584      max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 30, 51, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 30, 51, 128)  147584      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 30, 51, 128)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 30, 51, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 30, 51, 128)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 15, 25, 128)  0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 25, 128)  0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 15, 25, 128)  0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 15, 25, 128)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 15, 25, 128)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 15, 25, 128)  0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 13, 23, 256)  295168      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, 23, 256)  295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 13, 23, 256)  295168      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 13, 23, 256)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 13, 23, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 13, 23, 256)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 13, 23, 256)  0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 13, 23, 256)  0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 13, 23, 256)  0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 76544)        0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 76544)        0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 76544)        0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          39191040    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          39191040    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          39191040    flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 512)          0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512)          0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 512)          0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1536)         0           dropout_3[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 1536)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          393472      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           4112        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            34          dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 119,318,194\n",
      "Trainable params: 119,318,194\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cqt_order_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <tensorflow.python.keras.engine.training.Model object at 0x7f7d6f740160>>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cqt_order_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save = ModelCheckpoint('spec-augment-only-aug-30-epoch-self-supervised-temporal-order--6-14b.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=.2, \n",
    "                                  patience=1, \n",
    "                                  verbose=0, \n",
    "                                  mode='auto', \n",
    "                                  min_delta=0.00001, \n",
    "                                  cooldown=0, \n",
    "                                  min_lr=0)\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birds_home = os.path.join('/home/pattyry/birds/')\n",
    "#cwd_audio = os.path.join(\"..\",\"..\",\"birds\")\n",
    "os.chdir(birds_home)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4578 samples, validate on 1467 samples\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"dense_5_sample_weights:0\", shape=(?,), dtype=float32) must be from the same graph as Tensor(\"Mean_1:0\", shape=(?,), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/api/_v1/keras/losses/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_x_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_x_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_x_3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                          class_weight=class_weight)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;31m# Get step function and loop type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m   \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0muse_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_dataset\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(model, mode)\u001b[0m\n\u001b[1;32m    530\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistributed_training_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_execution_function\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m   2274\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_execution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2276\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2277\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2200\u001b[0;31m     \u001b[0mhas_recompiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recompile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2201\u001b[0m     metrics_tensors = [\n\u001b[1;32m   2202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_metrics_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_recompile_weights_loss_and_weighted_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrecompile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1684\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_weights_loss_and_weighted_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1685\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrecompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_compile_weights_loss_and_weighted_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1708\u001b[0m       \u001b[0;31m#                   loss_weight_2 * output_2_loss_fn(...) +\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m       \u001b[0;31m#                   layer losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1710\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_total_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_skip_target_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_prepare_total_loss\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m   1772\u001b[0m                 \u001b[0mper_sample_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m                 reduction=losses_utils.ReductionV2.NONE)\n\u001b[0m\u001b[1;32m   1775\u001b[0m             \u001b[0mloss_reduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py\u001b[0m in \u001b[0;36mcompute_weighted_loss\u001b[0;34m(losses, sample_weight, reduction, name)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0msample_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mweighted_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;31m# Apply reduction function to the individual weighted losses.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce_weighted_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmultiply\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6488\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6489\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6490\u001b[0;31m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   6491\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6492\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    364\u001b[0m       \u001b[0;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m       \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m       \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[0;34m(op_input_list, graph)\u001b[0m\n\u001b[1;32m   6133\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6134\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6135\u001b[0;31m         \u001b[0m_assert_same_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6136\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6137\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[0;34m(original_item, item)\u001b[0m\n\u001b[1;32m   6069\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6070\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" %\n\u001b[0;32m-> 6071\u001b[0;31m                      (item, original_item))\n\u001b[0m\u001b[1;32m   6072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor(\"dense_5_sample_weights:0\", shape=(?,), dtype=float32) must be from the same graph as Tensor(\"Mean_1:0\", shape=(?,), dtype=float32)."
     ]
    }
   ],
   "source": [
    "history = cqt_order_model.fit([train_x_1, train_x_2, train_x_3],[to_categorical(train_y_)], \n",
    "                         epochs=10,\n",
    "                         #verbose=2, \n",
    "                         batch_size=240,\n",
    "                         validation_data=([test_x_1, test_x_2,test_x_3], to_categorical(test_y_)),\n",
    "                         callbacks=[mcp_save, reduce_lr],\n",
    "                         class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/anaconda3/envs/gansynth/bin'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "os.path.dirname(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "os.chdir(birds_home)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('spec-augment-only-aug-self-supervised-temporal-order--6-14b.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = keras.Input(shape =(cqt_input_shape))\n",
    "x2 = keras.Input(shape =(cqt_input_shape))\n",
    "x3 = keras.Input(shape =(cqt_input_shape))\n",
    "\n",
    "inputs=[x1, x2, x3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_1': <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f7a2d325550>, 'input_2': <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f7a2d325668>, 'input_3': <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f7a2d3257b8>, 'leaky_re_lu': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d325b38>, 'leaky_re_lu_5': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d307198>, 'leaky_re_lu_10': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d3071d0>, 'conv2d': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d307400>, 'conv2d_3': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d3078d0>, 'conv2d_6': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d307da0>, 'dropout': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d3732b0>, 'dropout_4': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d373400>, 'dropout_8': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d373550>, 'leaky_re_lu_1': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d3736a0>, 'leaky_re_lu_6': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d3737f0>, 'leaky_re_lu_11': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d373940>, 'max_pooling2d': <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7a2d373a90>, 'max_pooling2d_2': <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7a2d373d30>, 'max_pooling2d_4': <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7a2d373fd0>, 'conv2d_1': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d36d2b0>, 'conv2d_4': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d36d780>, 'conv2d_7': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d36dc50>, 'leaky_re_lu_2': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d369160>, 'leaky_re_lu_7': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d3692b0>, 'leaky_re_lu_12': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d369400>, 'max_pooling2d_1': <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7a2d369550>, 'max_pooling2d_3': <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7a2d3697f0>, 'max_pooling2d_5': <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f7a2d369a90>, 'dropout_1': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d369d30>, 'dropout_5': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d369e80>, 'dropout_9': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d369fd0>, 'conv2d_2': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d363160>, 'conv2d_5': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d363630>, 'conv2d_8': <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f7a2d363b00>, 'leaky_re_lu_3': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d363fd0>, 'leaky_re_lu_8': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d35f160>, 'leaky_re_lu_13': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d35f2b0>, 'dropout_2': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d35f400>, 'dropout_6': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d35f550>, 'dropout_10': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d35f6a0>, 'flatten': <tensorflow.python.keras.layers.core.Flatten object at 0x7f7a2d35f7f0>, 'flatten_1': <tensorflow.python.keras.layers.core.Flatten object at 0x7f7a2d35f978>, 'flatten_2': <tensorflow.python.keras.layers.core.Flatten object at 0x7f7a2d35fb00>, 'dense': <tensorflow.python.keras.layers.core.Dense object at 0x7f7a2d35fc88>, 'dense_1': <tensorflow.python.keras.layers.core.Dense object at 0x7f7a2d35ffd0>, 'dense_2': <tensorflow.python.keras.layers.core.Dense object at 0x7f7a2d358358>, 'leaky_re_lu_4': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d3586a0>, 'leaky_re_lu_9': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d3587f0>, 'leaky_re_lu_14': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d358940>, 'dropout_3': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d358a90>, 'dropout_7': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d358be0>, 'dropout_11': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d358d30>, 'concatenate': <tensorflow.python.keras.layers.merge.Concatenate object at 0x7f7a2d358e80>, 'leaky_re_lu_15': <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7f7a2d335048>, 'dense_3': <tensorflow.python.keras.layers.core.Dense object at 0x7f7a2d335208>, 'dropout_12': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d335550>, 'dense_4': <tensorflow.python.keras.layers.core.Dense object at 0x7f7a2d3356a0>, 'dropout_13': <tensorflow.python.keras.layers.core.Dropout object at 0x7f7a2d335a20>, 'dense_5': <tensorflow.python.keras.layers.core.Dense object at 0x7f7a2d335b70>}\n"
     ]
    }
   ],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "print(layer_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[array([[[[ 0.20344156, -0.14032693,  0.00159053, ...,  0.13990973,\n",
      "          -0.21145575,  0.04415479]],\n",
      "\n",
      "        [[ 0.14212193, -0.10969139,  0.16181007, ..., -0.1959698 ,\n",
      "           0.00369271, -0.1389219 ]],\n",
      "\n",
      "        [[ 0.09005121, -0.03220682, -0.13282958, ...,  0.19589102,\n",
      "          -0.13432182,  0.03865555]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.12228387,  0.24794593, -0.17312826, ..., -0.00504658,\n",
      "          -0.11565565, -0.00908625]],\n",
      "\n",
      "        [[ 0.07937154, -0.17696281,  0.01539742, ...,  0.04942805,\n",
      "          -0.14245293, -0.14681588]],\n",
      "\n",
      "        [[ 0.08577465,  0.01018034,  0.03560253, ..., -0.08745713,\n",
      "          -0.10268371,  0.06127718]]],\n",
      "\n",
      "\n",
      "       [[[-0.24913326,  0.19086069, -0.06165431, ...,  0.01767287,\n",
      "          -0.10228569,  0.01031246]],\n",
      "\n",
      "        [[ 0.02302524, -0.17885692,  0.09230433, ...,  0.22210121,\n",
      "           0.21857555,  0.16122156]],\n",
      "\n",
      "        [[ 0.08564146,  0.07462309, -0.04462932, ..., -0.18619391,\n",
      "           0.00937441, -0.0192873 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.26078248, -0.07590015,  0.02379199, ...,  0.00960033,\n",
      "          -0.02356274, -0.00259919]],\n",
      "\n",
      "        [[ 0.08552652,  0.0416249 , -0.00074575, ...,  0.25064486,\n",
      "           0.0256728 ,  0.25268632]],\n",
      "\n",
      "        [[ 0.05929078,  0.09311096, -0.00317466, ...,  0.161062  ,\n",
      "          -0.06007414, -0.0433554 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.03751412,  0.24350543,  0.09567795, ...,  0.05386169,\n",
      "          -0.02467597, -0.08831766]],\n",
      "\n",
      "        [[-0.14418143, -0.08760581,  0.03366129, ...,  0.05958871,\n",
      "           0.28025654, -0.15742575]],\n",
      "\n",
      "        [[ 0.00574811,  0.0846058 ,  0.13174032, ...,  0.13503398,\n",
      "          -0.22078736, -0.00821273]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.07646379,  0.04888817,  0.13899408, ...,  0.18815807,\n",
      "           0.01980291,  0.11520566]],\n",
      "\n",
      "        [[ 0.25651288,  0.00035931,  0.0880208 , ..., -0.15477017,\n",
      "          -0.06674456,  0.22481376]],\n",
      "\n",
      "        [[ 0.02682707, -0.020573  ,  0.0684669 , ..., -0.13558143,\n",
      "           0.07519905,  0.16513163]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[-0.02657963,  0.0614173 , -0.02878941, ..., -0.00504692,\n",
      "          -0.09039903,  0.02516118]],\n",
      "\n",
      "        [[-0.15271011, -0.03276251, -0.02224249, ..., -0.0849157 ,\n",
      "          -0.04029151, -0.08113581]],\n",
      "\n",
      "        [[ 0.21209887, -0.02845958,  0.1835108 , ..., -0.18086162,\n",
      "           0.15949817,  0.2346244 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.21255587, -0.15680166, -0.18975638, ...,  0.22812621,\n",
      "          -0.17389363, -0.01628027]],\n",
      "\n",
      "        [[-0.04710718, -0.02548954, -0.05939357, ...,  0.14593516,\n",
      "          -0.08844653,  0.04763095]],\n",
      "\n",
      "        [[-0.08110708,  0.09102746,  0.09500792, ...,  0.09578034,\n",
      "          -0.0389272 ,  0.17977831]]],\n",
      "\n",
      "\n",
      "       [[[-0.09302329,  0.02662711,  0.03411018, ...,  0.04020952,\n",
      "           0.08221621,  0.14262372]],\n",
      "\n",
      "        [[-0.03404611, -0.06344526, -0.04742213, ...,  0.06021897,\n",
      "           0.03664122, -0.1335036 ]],\n",
      "\n",
      "        [[-0.06106265, -0.17075603,  0.18812571, ...,  0.04905368,\n",
      "           0.0841461 , -0.05067836]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2444131 , -0.0565024 , -0.19146082, ..., -0.0472545 ,\n",
      "          -0.01628839, -0.0245533 ]],\n",
      "\n",
      "        [[ 0.05922221, -0.15880711, -0.11045432, ...,  0.1881911 ,\n",
      "          -0.07053788,  0.06068367]],\n",
      "\n",
      "        [[-0.07165845, -0.142423  , -0.06566931, ...,  0.05691656,\n",
      "          -0.18290627,  0.00118855]]],\n",
      "\n",
      "\n",
      "       [[[-0.01242649, -0.03148361, -0.02538076, ...,  0.00729751,\n",
      "           0.19120571, -0.03580773]],\n",
      "\n",
      "        [[-0.09263896,  0.01155842, -0.16817786, ...,  0.18835868,\n",
      "           0.0184942 ,  0.10774118]],\n",
      "\n",
      "        [[ 0.19380896,  0.08527803,  0.02751913, ..., -0.02565193,\n",
      "           0.2801542 , -0.05898971]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.19120589,  0.06544558, -0.02761444, ..., -0.12072548,\n",
      "           0.05525996,  0.00981625]],\n",
      "\n",
      "        [[-0.16913475, -0.07210259, -0.15425839, ...,  0.2076524 ,\n",
      "           0.06127165, -0.01650072]],\n",
      "\n",
      "        [[ 0.12102957, -0.01899148,  0.16071318, ...,  0.09983787,\n",
      "          -0.1164824 ,  0.24519703]]]], dtype=float32), array([-0.01184186, -0.00586363, -0.00441825, -0.00072963, -0.0063171 ,\n",
      "       -0.00462754, -0.00290536, -0.00317059, -0.00158698, -0.01099605,\n",
      "       -0.00556172, -0.00855327, -0.00324533, -0.00760504, -0.00635115,\n",
      "       -0.00322846, -0.00246117, -0.0053511 ,  0.00177987, -0.00827217,\n",
      "       -0.01124235, -0.0067934 , -0.00802746,  0.01058871, -0.00453459,\n",
      "       -0.00340058, -0.00734828, -0.00242486,  0.00168929, -0.01372272,\n",
      "       -0.01426456, -0.0021072 , -0.00290535,  0.00115954, -0.00583615,\n",
      "       -0.01140373,  0.01068615, -0.00683863, -0.01037524, -0.00319198,\n",
      "       -0.00522563, -0.00558602,  0.01472103, -0.00264176, -0.00631947,\n",
      "        0.00666949, -0.00484447, -0.00894226,  0.00870092,  0.01192288,\n",
      "        0.01182344, -0.01076312, -0.0110228 , -0.00031505, -0.00605306,\n",
      "       -0.00479986,  0.00338551, -0.0050567 ,  0.00045199, -0.00586111,\n",
      "       -0.00352604, -0.00551472, -0.00084059,  0.00393655, -0.00685421,\n",
      "        0.01092979,  0.00159785, -0.01059095, -0.00828071, -0.0129732 ,\n",
      "       -0.00580473,  0.00969892,  0.01137871, -0.00436235, -0.00409421,\n",
      "        0.00545692, -0.01214731, -0.01160362, -0.00515914, -0.00345264,\n",
      "       -0.00424096, -0.00693273, -0.00888213,  0.01300823, -0.00330948,\n",
      "       -0.00520293, -0.00253499,  0.00152751,  0.00859588, -0.00507127,\n",
      "       -0.00505858, -0.00776796, -0.00622455, -0.00698962, -0.00554625,\n",
      "       -0.00417055, -0.00280735,  0.00147817,  0.00636019, -0.00613487,\n",
      "       -0.00036257, -0.00457596,  0.00950514,  0.00765751, -0.0053661 ,\n",
      "       -0.00589761,  0.00326035,  0.01412401, -0.0073433 ,  0.01581927,\n",
      "       -0.00757439,  0.00859109, -0.01035162, -0.00661547, -0.01142599,\n",
      "        0.01074233, -0.00483829,  0.00242794, -0.00502466,  0.0008289 ,\n",
      "       -0.00259056, -0.00703122, -0.00878746,  0.00967421,  0.00194202,\n",
      "       -0.00891702,  0.01064773, -0.00566631], dtype=float32)]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[array([[[[-0.01274797, -0.01750015, -0.0032456 , ...,  0.01181622,\n",
      "          -0.05759988,  0.00761262],\n",
      "         [ 0.00040183, -0.01549938, -0.00476371, ...,  0.01261942,\n",
      "           0.00787359,  0.00830912],\n",
      "         [ 0.00261837,  0.01287883, -0.00297042, ...,  0.01142274,\n",
      "           0.04355244, -0.00182737],\n",
      "         ...,\n",
      "         [-0.03145869, -0.03961362,  0.01442884, ..., -0.00159864,\n",
      "          -0.00571997, -0.00309643],\n",
      "         [-0.02546388,  0.02249187,  0.01070279, ...,  0.02995386,\n",
      "           0.00886253,  0.01235044],\n",
      "         [-0.0182313 ,  0.00215853,  0.00785278, ..., -0.02134913,\n",
      "          -0.00281625,  0.02463979]],\n",
      "\n",
      "        [[-0.06124048,  0.01429699, -0.00738343, ...,  0.03804845,\n",
      "          -0.06115933, -0.00475556],\n",
      "         [ 0.00996799, -0.0062937 ,  0.00105936, ..., -0.00928753,\n",
      "           0.01845692,  0.01483131],\n",
      "         [-0.01087578, -0.00290985, -0.00418177, ...,  0.01396103,\n",
      "          -0.03714573, -0.01887774],\n",
      "         ...,\n",
      "         [ 0.0180684 ,  0.01397017,  0.02801051, ..., -0.03895741,\n",
      "           0.05351716,  0.0097995 ],\n",
      "         [ 0.00888904,  0.02188873, -0.00974156, ..., -0.00610184,\n",
      "           0.02541162, -0.0006468 ],\n",
      "         [ 0.02872192, -0.01780498, -0.01769705, ..., -0.04237462,\n",
      "          -0.00438803,  0.00345325]],\n",
      "\n",
      "        [[-0.00516423, -0.01687338, -0.04394853, ..., -0.0555485 ,\n",
      "          -0.00656885,  0.02169844],\n",
      "         [-0.0002082 ,  0.01969809, -0.00255956, ..., -0.00751775,\n",
      "          -0.00858783,  0.01415546],\n",
      "         [ 0.00264176, -0.01817911,  0.01671539, ...,  0.00868129,\n",
      "           0.03075453,  0.02065412],\n",
      "         ...,\n",
      "         [ 0.00632122, -0.00507774, -0.01343305, ..., -0.00210487,\n",
      "           0.02343861, -0.00375096],\n",
      "         [-0.00648037,  0.0137033 , -0.01795595, ..., -0.00801437,\n",
      "           0.00921225, -0.01379761],\n",
      "         [ 0.01161742,  0.01303728, -0.02325365, ...,  0.00056841,\n",
      "          -0.02596469, -0.025501  ]]],\n",
      "\n",
      "\n",
      "       [[[-0.00363059, -0.00024769,  0.01573752, ..., -0.04785674,\n",
      "          -0.00057958,  0.02211987],\n",
      "         [ 0.00617106,  0.01082103, -0.00266103, ...,  0.00046016,\n",
      "           0.00038836, -0.01133615],\n",
      "         [ 0.00887624,  0.02153439, -0.02172367, ...,  0.01541358,\n",
      "          -0.00516073,  0.028558  ],\n",
      "         ...,\n",
      "         [ 0.01035905,  0.02898639, -0.02566892, ..., -0.00063234,\n",
      "          -0.00588884,  0.00339888],\n",
      "         [-0.00628206, -0.02919672,  0.04479545, ...,  0.00581085,\n",
      "          -0.04235919, -0.00273959],\n",
      "         [-0.0494056 , -0.0177444 ,  0.0148406 , ...,  0.00316794,\n",
      "          -0.00078548, -0.02151999]],\n",
      "\n",
      "        [[-0.02153806,  0.0063062 ,  0.0006391 , ...,  0.03972475,\n",
      "           0.02998287, -0.0224    ],\n",
      "         [-0.00338773, -0.00042008, -0.0033692 , ...,  0.01081082,\n",
      "          -0.01654826,  0.01141818],\n",
      "         [-0.00727325,  0.01007475, -0.00644845, ...,  0.03673575,\n",
      "          -0.02412429,  0.00758664],\n",
      "         ...,\n",
      "         [-0.01085681, -0.00277204, -0.00131565, ...,  0.02076685,\n",
      "           0.00786328, -0.00294742],\n",
      "         [-0.02729162, -0.03418817, -0.01860517, ..., -0.0351142 ,\n",
      "           0.00978605, -0.01800071],\n",
      "         [-0.03095551,  0.00817359, -0.03531276, ...,  0.00677547,\n",
      "          -0.03634617,  0.04383992]],\n",
      "\n",
      "        [[-0.00431247,  0.00658209,  0.02191735, ...,  0.02028335,\n",
      "           0.00751311,  0.0512724 ],\n",
      "         [ 0.00402835,  0.00440592, -0.00480916, ..., -0.00198062,\n",
      "          -0.00725212, -0.00461598],\n",
      "         [-0.0150673 ,  0.01196984, -0.0099953 , ...,  0.03433517,\n",
      "           0.02644688, -0.0095024 ],\n",
      "         ...,\n",
      "         [-0.02816083, -0.01096746, -0.00535576, ...,  0.03257636,\n",
      "          -0.05212878,  0.03623858],\n",
      "         [-0.00002544, -0.00430053,  0.03660965, ..., -0.01522879,\n",
      "           0.01598126, -0.00685334],\n",
      "         [ 0.00682523, -0.00434388,  0.00243612, ...,  0.00229311,\n",
      "          -0.00076917, -0.02397605]]],\n",
      "\n",
      "\n",
      "       [[[-0.00484692, -0.0112535 ,  0.02259467, ...,  0.0086323 ,\n",
      "          -0.0336018 ,  0.01530464],\n",
      "         [-0.00314373,  0.00991651, -0.0084624 , ...,  0.0083808 ,\n",
      "           0.01545734,  0.00878672],\n",
      "         [ 0.03204028,  0.00015342, -0.01640558, ..., -0.01586165,\n",
      "          -0.00749731,  0.00725044],\n",
      "         ...,\n",
      "         [ 0.04316982, -0.01965664, -0.0037473 , ..., -0.01878878,\n",
      "          -0.009258  , -0.0584103 ],\n",
      "         [-0.00336527,  0.00507983, -0.00354646, ..., -0.03320838,\n",
      "           0.01742508, -0.01997069],\n",
      "         [-0.02957176,  0.02148165, -0.00935626, ...,  0.00878335,\n",
      "          -0.02286259, -0.01102734]],\n",
      "\n",
      "        [[-0.02244416,  0.00923487, -0.01118695, ...,  0.00114257,\n",
      "          -0.01345445, -0.05689078],\n",
      "         [-0.01100239,  0.00297632,  0.01484041, ..., -0.00321202,\n",
      "           0.00831289,  0.00894937],\n",
      "         [-0.02219406,  0.00888297,  0.00422806, ...,  0.01757397,\n",
      "           0.0520511 , -0.01532975],\n",
      "         ...,\n",
      "         [-0.0366535 ,  0.00478877, -0.00981442, ..., -0.0150435 ,\n",
      "          -0.00784534,  0.01865866],\n",
      "         [ 0.01740092, -0.03601036,  0.00295167, ...,  0.02539971,\n",
      "          -0.02422122,  0.00206786],\n",
      "         [ 0.00663918,  0.03509028, -0.02627306, ...,  0.00781628,\n",
      "          -0.01092816,  0.00349464]],\n",
      "\n",
      "        [[-0.04631162, -0.00113952,  0.01862743, ..., -0.03848263,\n",
      "           0.03206592,  0.01184578],\n",
      "         [ 0.01563511,  0.00013858, -0.00628143, ..., -0.01112947,\n",
      "           0.01954475,  0.00212037],\n",
      "         [ 0.01580421,  0.02636129,  0.01567616, ...,  0.02780175,\n",
      "          -0.0203694 ,  0.00596   ],\n",
      "         ...,\n",
      "         [-0.05310017,  0.00070432, -0.03516881, ..., -0.01249749,\n",
      "          -0.02457319,  0.02199139],\n",
      "         [ 0.01002405,  0.00346395, -0.01289214, ...,  0.01834026,\n",
      "          -0.01905156, -0.0124191 ],\n",
      "         [-0.04405356, -0.0384289 , -0.02978036, ..., -0.00805799,\n",
      "          -0.0482161 , -0.03833145]]]], dtype=float32), array([-0.00306164, -0.00576156,  0.007366  ,  0.00321478, -0.00644378,\n",
      "       -0.00308059, -0.00040366,  0.00485817,  0.00333193, -0.00700917,\n",
      "        0.00199252,  0.00603514, -0.00233024, -0.00473583, -0.00084202,\n",
      "       -0.00209414, -0.00661831, -0.00028531,  0.00347731, -0.00356151,\n",
      "        0.00535273, -0.00281878, -0.00089036,  0.00003238, -0.00092186,\n",
      "        0.0035637 ,  0.00348046, -0.0105194 ,  0.00298797, -0.00514438,\n",
      "       -0.0040685 ,  0.00530917, -0.00444542, -0.00270197, -0.00357264,\n",
      "        0.01147601, -0.00760202, -0.00326306, -0.00473563, -0.00420615,\n",
      "       -0.00609886,  0.00319507, -0.00136048, -0.00439961, -0.00060016,\n",
      "        0.00031584, -0.00804651, -0.00437042, -0.00770577, -0.00415567,\n",
      "       -0.00422402, -0.00224054,  0.00503499, -0.00282136, -0.0032802 ,\n",
      "       -0.00499098, -0.00277185,  0.00433243, -0.00621941, -0.0046043 ,\n",
      "       -0.00453065, -0.00267569, -0.00820656, -0.00324686, -0.00424899,\n",
      "        0.0014116 ,  0.00703068, -0.00807001,  0.00181567,  0.00548703,\n",
      "       -0.00474211, -0.00384198,  0.00672869, -0.00237795, -0.00190049,\n",
      "       -0.00311683, -0.00442817,  0.00015611, -0.00295496, -0.0031635 ,\n",
      "       -0.00624232,  0.00256306, -0.00246772,  0.00151161, -0.00460515,\n",
      "        0.00258101, -0.00110136,  0.0068256 , -0.00592917, -0.00120585,\n",
      "        0.00478824,  0.00332032, -0.00378385,  0.00053347, -0.00155724,\n",
      "       -0.00265623, -0.00144203,  0.00146642, -0.00252123,  0.00022099,\n",
      "       -0.00025869, -0.00306109,  0.0014316 ,  0.00477344,  0.00619777,\n",
      "       -0.005019  , -0.00350258,  0.00369648, -0.00442714, -0.00617525,\n",
      "       -0.00085998, -0.00226144, -0.00590206, -0.00114266, -0.00749706,\n",
      "       -0.00529076, -0.00232912, -0.00164042, -0.0007293 , -0.00099945,\n",
      "       -0.0034707 ,  0.00087797, -0.00530855, -0.00365602, -0.00366722,\n",
      "       -0.00556434, -0.0010296 , -0.00163304], dtype=float32)]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[ 0.00513944,  0.00474862,  0.01245621, ...,  0.00763899,\n",
      "           0.01000646, -0.00038219],\n",
      "         [-0.00184024, -0.00986486,  0.01281886, ...,  0.01952427,\n",
      "           0.0108036 , -0.00762373],\n",
      "         [ 0.00771981, -0.00473628, -0.0175372 , ..., -0.00445185,\n",
      "          -0.01025867, -0.01352853],\n",
      "         ...,\n",
      "         [-0.01458863, -0.01428088, -0.00522701, ..., -0.01526715,\n",
      "          -0.00844157, -0.00252435],\n",
      "         [-0.00645196,  0.02031715, -0.0066627 , ..., -0.02447101,\n",
      "           0.04493306, -0.0007815 ],\n",
      "         [ 0.00089813, -0.02656673,  0.01490098, ...,  0.011683  ,\n",
      "          -0.01231718,  0.0095048 ]],\n",
      "\n",
      "        [[-0.01677419,  0.0208605 ,  0.01219983, ...,  0.00718892,\n",
      "          -0.00313994,  0.00678297],\n",
      "         [ 0.02544815, -0.00732442, -0.00506847, ...,  0.02711425,\n",
      "          -0.01220124,  0.01452733],\n",
      "         [ 0.01427806, -0.01392645,  0.00802844, ..., -0.01712665,\n",
      "          -0.00281863,  0.00790989],\n",
      "         ...,\n",
      "         [ 0.03212005,  0.0057919 , -0.00544708, ..., -0.00386123,\n",
      "           0.00554811, -0.00056994],\n",
      "         [ 0.00080624,  0.02028387, -0.00137709, ...,  0.01646182,\n",
      "           0.00839177, -0.00283599],\n",
      "         [-0.00961311, -0.00901578, -0.02718079, ...,  0.00872803,\n",
      "           0.0075837 ,  0.01733745]],\n",
      "\n",
      "        [[ 0.00168204,  0.01066619, -0.00162843, ..., -0.00932381,\n",
      "          -0.04832532, -0.00499728],\n",
      "         [-0.00016956, -0.01855702,  0.01018711, ...,  0.00053558,\n",
      "           0.03311992, -0.02923566],\n",
      "         [-0.00184368, -0.00083924, -0.00952217, ..., -0.00669232,\n",
      "          -0.02817638, -0.01243479],\n",
      "         ...,\n",
      "         [-0.03121135,  0.02568243,  0.02290506, ...,  0.02061877,\n",
      "           0.03711049, -0.01032914],\n",
      "         [ 0.01594144,  0.02906961, -0.01271119, ...,  0.00416776,\n",
      "           0.01608404, -0.00069296],\n",
      "         [-0.01191951, -0.02748825, -0.00430417, ...,  0.00340858,\n",
      "           0.04318714, -0.01726716]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00389849,  0.0024286 , -0.00836344, ...,  0.01504809,\n",
      "          -0.00879572, -0.00027397],\n",
      "         [-0.01253392, -0.02240382,  0.01582664, ...,  0.01756765,\n",
      "           0.01083644, -0.00833022],\n",
      "         [-0.01480757,  0.00240704, -0.00569121, ..., -0.01472915,\n",
      "           0.00014521, -0.00937514],\n",
      "         ...,\n",
      "         [ 0.01633546, -0.01673839, -0.01891181, ..., -0.0020788 ,\n",
      "           0.02580629,  0.00457958],\n",
      "         [-0.01143092, -0.00507169,  0.01496571, ...,  0.02448428,\n",
      "           0.01486244,  0.00163586],\n",
      "         [ 0.01677752, -0.01043794, -0.00919564, ...,  0.00733722,\n",
      "          -0.00926878, -0.01036367]],\n",
      "\n",
      "        [[ 0.01062923,  0.02879336,  0.02741277, ..., -0.03062893,\n",
      "          -0.02945767, -0.00090868],\n",
      "         [ 0.01957755,  0.00512588,  0.02033887, ..., -0.00311459,\n",
      "          -0.00953576, -0.00186873],\n",
      "         [ 0.00565871,  0.00237276,  0.00359628, ..., -0.02091851,\n",
      "           0.00691655, -0.00449812],\n",
      "         ...,\n",
      "         [-0.03442284, -0.00715162, -0.00882654, ..., -0.01508338,\n",
      "          -0.0316854 , -0.02161299],\n",
      "         [ 0.00548226,  0.02040372,  0.03142112, ...,  0.00012052,\n",
      "           0.00411727, -0.01309154],\n",
      "         [ 0.03181156, -0.01483589, -0.02153408, ..., -0.0065103 ,\n",
      "           0.00146925, -0.03288825]],\n",
      "\n",
      "        [[ 0.00289304,  0.02038513, -0.00216593, ..., -0.00850859,\n",
      "           0.02256988,  0.00471273],\n",
      "         [ 0.00045701,  0.02119216,  0.01178503, ...,  0.01786671,\n",
      "           0.04131975, -0.00596333],\n",
      "         [ 0.01447233, -0.01445081, -0.00946809, ..., -0.00452775,\n",
      "          -0.00572341, -0.01029969],\n",
      "         ...,\n",
      "         [-0.00292314, -0.03187469,  0.01564691, ..., -0.01467776,\n",
      "          -0.02207987,  0.0048373 ],\n",
      "         [-0.00008177,  0.02568494, -0.01002193, ..., -0.01461998,\n",
      "           0.00318485, -0.00594681],\n",
      "         [ 0.00877565,  0.01976676, -0.02067527, ...,  0.01327044,\n",
      "           0.00622752,  0.0185409 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00181949, -0.02846053, -0.02533901, ..., -0.0073945 ,\n",
      "           0.01252352, -0.00570648],\n",
      "         [-0.00000796,  0.01210331, -0.00381262, ...,  0.03223961,\n",
      "           0.00222726, -0.0028999 ],\n",
      "         [ 0.01164998,  0.01078254, -0.00169917, ...,  0.00173886,\n",
      "           0.00367215,  0.00993069],\n",
      "         ...,\n",
      "         [-0.01544315, -0.04173438,  0.00013238, ...,  0.00775253,\n",
      "          -0.00862544, -0.01034079],\n",
      "         [-0.02767782,  0.02820301, -0.00438418, ..., -0.00128391,\n",
      "          -0.02107836, -0.00336776],\n",
      "         [-0.00940552, -0.02217955, -0.01114647, ...,  0.00673708,\n",
      "           0.02805669, -0.00528261]],\n",
      "\n",
      "        [[-0.00581369,  0.01821237, -0.03226506, ...,  0.00345775,\n",
      "          -0.01450897,  0.00083506],\n",
      "         [-0.00484255,  0.01706507,  0.00478831, ...,  0.00954173,\n",
      "           0.01355653, -0.00705965],\n",
      "         [-0.01263062,  0.01300108, -0.0072763 , ..., -0.01318857,\n",
      "          -0.00932285,  0.00296462],\n",
      "         ...,\n",
      "         [-0.00502571,  0.02195894, -0.01438368, ...,  0.0142226 ,\n",
      "           0.02247941, -0.00083751],\n",
      "         [-0.02885487,  0.00744063,  0.03803311, ...,  0.00108315,\n",
      "           0.01930644, -0.02334579],\n",
      "         [-0.02833097, -0.01553523,  0.0099165 , ..., -0.01971315,\n",
      "          -0.01579149, -0.01935586]],\n",
      "\n",
      "        [[-0.00015441, -0.0225389 ,  0.03003269, ...,  0.00243888,\n",
      "          -0.01977463, -0.00092836],\n",
      "         [-0.01208753,  0.00667654, -0.00019716, ..., -0.00643728,\n",
      "          -0.03086523,  0.00819908],\n",
      "         [-0.00876451, -0.02833416,  0.00437406, ..., -0.00359948,\n",
      "           0.00330776, -0.0121947 ],\n",
      "         ...,\n",
      "         [-0.01110719,  0.03768598,  0.00244523, ..., -0.0102061 ,\n",
      "          -0.00963468, -0.00702629],\n",
      "         [-0.00514251, -0.00094167,  0.02342214, ...,  0.01002803,\n",
      "          -0.00396938, -0.02711187],\n",
      "         [ 0.00568984,  0.00172438, -0.01818582, ...,  0.00330175,\n",
      "          -0.0155292 ,  0.01169714]]]], dtype=float32), array([ 0.00048081,  0.00537341, -0.01023656, -0.01134442, -0.00716715,\n",
      "       -0.0039416 , -0.00126232, -0.00492089, -0.00583098,  0.01178973,\n",
      "       -0.00382337, -0.00258729, -0.00203323, -0.00052483,  0.00150324,\n",
      "       -0.00668608, -0.00296489, -0.00792054,  0.00471704,  0.00226781,\n",
      "       -0.00316878, -0.01112941, -0.00265454, -0.00295056,  0.00001239,\n",
      "        0.01103003, -0.00094282,  0.00868378, -0.00791644,  0.00302579,\n",
      "       -0.00384986, -0.00684783,  0.01093984, -0.00290191, -0.00113589,\n",
      "       -0.00361749, -0.00032049, -0.00141583, -0.00389159,  0.00920379,\n",
      "       -0.00432913, -0.00212995,  0.00273429, -0.00122719, -0.00489612,\n",
      "       -0.00389642, -0.00406348, -0.00712021, -0.00498956, -0.00102453,\n",
      "       -0.00815793, -0.00606457,  0.00160131, -0.00053656, -0.00435127,\n",
      "        0.00864308, -0.0077472 ,  0.00648263, -0.00232242,  0.00470562,\n",
      "       -0.00521394, -0.00195845, -0.00102674,  0.00382181, -0.00408394,\n",
      "       -0.00008063,  0.00463972, -0.00400941, -0.00473272, -0.00211752,\n",
      "       -0.00896064, -0.00681279, -0.00162539, -0.00064053, -0.0029947 ,\n",
      "       -0.0023552 , -0.0095288 ,  0.00047913, -0.00521292, -0.00303649,\n",
      "       -0.00040601, -0.00395279, -0.00228127, -0.00060155, -0.00254836,\n",
      "       -0.01089551, -0.0035598 , -0.00035154, -0.00506322, -0.00846649,\n",
      "        0.00139742,  0.00277809, -0.00468147,  0.0004045 , -0.00843775,\n",
      "       -0.00209849, -0.00557934,  0.00245239,  0.00421613, -0.00615768,\n",
      "       -0.0053247 , -0.01084067, -0.00003819, -0.00415875, -0.00843744,\n",
      "       -0.00788816, -0.0014288 , -0.00335097, -0.00431868, -0.01004049,\n",
      "       -0.00673613, -0.00466269,  0.00266931, -0.00145483, -0.00516897,\n",
      "        0.00013786,  0.00057077, -0.00335247, -0.00308134, -0.00304023,\n",
      "       -0.00892951, -0.00315647, -0.00186062, -0.00377925, -0.00879415,\n",
      "       -0.00255027,  0.00370152, -0.00728933, -0.00583923, -0.00099579,\n",
      "       -0.0014751 , -0.0068173 ,  0.00172303, -0.01089846, -0.00025948,\n",
      "       -0.00554349, -0.00225573, -0.00646746, -0.00316585, -0.00443153,\n",
      "       -0.00096428,  0.00064699, -0.00519814,  0.00316633,  0.00043454,\n",
      "       -0.00242603, -0.00946059, -0.00535921, -0.00381016,  0.00575343,\n",
      "       -0.00513926, -0.00299249, -0.00742627, -0.00432381, -0.00008176,\n",
      "       -0.00189748, -0.00799832,  0.00137489, -0.00598274, -0.00709902,\n",
      "       -0.00176367, -0.00170524, -0.0041715 , -0.00685914,  0.00094967,\n",
      "        0.00074564, -0.00191951, -0.00164296,  0.00229138, -0.00661315,\n",
      "        0.00062204, -0.00376234,  0.00471801, -0.00430114, -0.00060248,\n",
      "       -0.00593714,  0.00269601, -0.00477198, -0.0060945 , -0.00291949,\n",
      "       -0.00867288, -0.0028812 ,  0.00377955, -0.00737539, -0.00457996,\n",
      "       -0.0063464 , -0.00426022, -0.00208927,  0.0030305 , -0.00356407,\n",
      "       -0.00297688, -0.00100073, -0.00060814, -0.00301404, -0.00434705,\n",
      "        0.00204731, -0.00651242, -0.00350051,  0.00848872, -0.00870485,\n",
      "       -0.00770562, -0.00285125, -0.00755032, -0.00078687, -0.0075463 ,\n",
      "       -0.00121259,  0.00296231, -0.00316442, -0.0051225 , -0.00019626,\n",
      "        0.00140216, -0.00159993,  0.00319415, -0.00233976, -0.00166348,\n",
      "        0.00390642, -0.00607883, -0.01342907,  0.00042415,  0.00118824,\n",
      "       -0.0037047 , -0.00338233, -0.00533131, -0.00564032, -0.00377695,\n",
      "        0.00143163, -0.0027647 ,  0.00139797, -0.00100255, -0.00532046,\n",
      "       -0.00391973, -0.00532035, -0.00585625,  0.00116528, -0.00528429,\n",
      "       -0.0065658 , -0.00422714,  0.00047859,  0.00408836,  0.00354554,\n",
      "       -0.00621302, -0.00180784, -0.00884719, -0.00578615, -0.00007808,\n",
      "       -0.00485476, -0.00028153,  0.00096382, -0.0039189 , -0.00087327,\n",
      "        0.00660498, -0.00421824, -0.00000114, -0.00264787, -0.00767985,\n",
      "        0.00162106], dtype=float32)]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.00033332,  0.00057715,  0.00128879, ..., -0.00047167,\n",
      "        -0.00003207,  0.00010454],\n",
      "       [-0.00181719,  0.00587172,  0.00047248, ...,  0.00022697,\n",
      "         0.00037298, -0.00334244],\n",
      "       [ 0.00037552,  0.00004229,  0.00112876, ..., -0.00110811,\n",
      "         0.00069491,  0.00223617],\n",
      "       ...,\n",
      "       [ 0.00009202,  0.00214761,  0.00044192, ..., -0.00063407,\n",
      "         0.00036445, -0.00075378],\n",
      "       [-0.00064835,  0.00159977,  0.00134262, ..., -0.00050995,\n",
      "        -0.0002528 , -0.00016015],\n",
      "       [-0.00103454,  0.00084928,  0.00080043, ..., -0.00096654,\n",
      "        -0.00014226, -0.00068665]], dtype=float32), array([ 0.00008462,  0.00138961,  0.00336087,  0.00485914,  0.00031483,\n",
      "        0.0049026 , -0.00117229,  0.00368856, -0.00623961, -0.00137114,\n",
      "        0.00037027,  0.00627798, -0.00338869, -0.00082213, -0.00145492,\n",
      "        0.00026201,  0.00889966, -0.0005831 ,  0.00013409,  0.00226381,\n",
      "        0.00022172, -0.00050769,  0.00469144,  0.00602235, -0.00385617,\n",
      "       -0.00786847, -0.0060908 , -0.00241105, -0.00262061,  0.00174839,\n",
      "       -0.0024485 ,  0.00003705,  0.00406626, -0.00115189, -0.00461034,\n",
      "        0.00175073, -0.00604972,  0.00134371,  0.00115691, -0.00243375,\n",
      "       -0.00047227, -0.0069081 ,  0.00185645, -0.0039479 , -0.00437266,\n",
      "        0.00165777, -0.00383107,  0.0024096 ,  0.00174912, -0.00810387,\n",
      "        0.00616293, -0.00602621, -0.00825927, -0.00138768, -0.00120958,\n",
      "       -0.00402852, -0.00550189, -0.00198014, -0.00260874, -0.00426532,\n",
      "       -0.00216752, -0.00344   , -0.00020756, -0.00835074,  0.00920823,\n",
      "       -0.00249562, -0.00226509, -0.00840797, -0.00531015,  0.0008148 ,\n",
      "       -0.00429755,  0.00106193,  0.00280644,  0.00409106, -0.00155608,\n",
      "        0.00020072, -0.00295753, -0.0053336 , -0.00385303,  0.00198172,\n",
      "       -0.00581853, -0.00082322, -0.00203008, -0.00783883, -0.00196176,\n",
      "        0.00182848, -0.00114064,  0.00850722,  0.00363854,  0.00430962,\n",
      "        0.00204001,  0.00782901,  0.00314076, -0.0034844 , -0.00239958,\n",
      "       -0.00001564, -0.00422917,  0.00143823,  0.00044749, -0.00164727,\n",
      "        0.00318454,  0.00583898,  0.00154922, -0.00717773, -0.00679087,\n",
      "       -0.00067519,  0.00657372, -0.0109893 ,  0.00273107,  0.00089574,\n",
      "       -0.00694649,  0.00212861,  0.00052593,  0.00640735, -0.00186347,\n",
      "        0.00437842, -0.00486254, -0.00348664, -0.00190438,  0.00133381,\n",
      "        0.00253595, -0.00411459, -0.00185324, -0.00390084, -0.00883487,\n",
      "       -0.00626175, -0.00027894,  0.0027657 ,  0.00667   , -0.00574503,\n",
      "       -0.00030581, -0.00698628, -0.00184246, -0.00674305, -0.0023588 ,\n",
      "       -0.0001746 , -0.0034966 , -0.00327384, -0.00789529, -0.00816816,\n",
      "       -0.00745546, -0.00067474, -0.00800721,  0.00404498, -0.00663209,\n",
      "       -0.00296666,  0.00424886,  0.00645763,  0.00727579, -0.00563184,\n",
      "       -0.00280505,  0.00037214, -0.00517979,  0.00296123,  0.00233822,\n",
      "       -0.00179594,  0.0000448 ,  0.00468258,  0.00520241,  0.00189351,\n",
      "       -0.00252578, -0.00016238, -0.00325185, -0.00169704, -0.00377579,\n",
      "        0.00786639, -0.00482275, -0.00017727,  0.00082191, -0.00168281,\n",
      "       -0.00395621, -0.00248065,  0.00026508, -0.00235496, -0.00321353,\n",
      "       -0.00135077, -0.00143825,  0.00079955, -0.0075908 , -0.00446301,\n",
      "       -0.00049985, -0.00614863, -0.00542739, -0.00270519, -0.00335065,\n",
      "       -0.00083248,  0.00074645, -0.0017318 ,  0.00398066,  0.00061564,\n",
      "        0.00441656,  0.00435304,  0.00062087, -0.00056325, -0.00205577,\n",
      "        0.00016484, -0.00505497, -0.00362435, -0.00452524, -0.0043274 ,\n",
      "       -0.00012787, -0.00266806, -0.00976194,  0.00779702, -0.00122403,\n",
      "        0.0029793 , -0.00293208, -0.00553666,  0.00048366,  0.00607285,\n",
      "        0.00078684,  0.0063473 , -0.00661713,  0.00115981,  0.00562643,\n",
      "       -0.00565752, -0.00571291, -0.00187033, -0.00635097, -0.00317004,\n",
      "       -0.00936158,  0.00082457, -0.00106221, -0.00570754,  0.00136766,\n",
      "       -0.00468263, -0.00096305, -0.00753175,  0.00032006,  0.00149649,\n",
      "       -0.00063426,  0.00406983, -0.00036815, -0.00376419, -0.00326924,\n",
      "        0.00068032, -0.00192211, -0.00250183, -0.00076733, -0.00926673,\n",
      "       -0.003518  ,  0.00739206,  0.00388452, -0.00109787, -0.00124986,\n",
      "        0.00031669,  0.00461557,  0.00562311,  0.0051491 , -0.00403313,\n",
      "       -0.00491251, -0.00643839,  0.00024606,  0.00158038,  0.00297537,\n",
      "       -0.00029382,  0.00242595, -0.00721128, -0.00283652,  0.00038211,\n",
      "       -0.00312136, -0.00486969, -0.0070395 , -0.00157557,  0.00232329,\n",
      "        0.00054038,  0.00182219,  0.00649905, -0.00227603, -0.0005688 ,\n",
      "       -0.00963596,  0.00086047,  0.00152044,  0.00247945, -0.00343253,\n",
      "       -0.00651166,  0.00748552,  0.01017263,  0.00202908,  0.00341217,\n",
      "       -0.00546844,  0.00258795,  0.00211147,  0.00467079,  0.004119  ,\n",
      "        0.00154661, -0.00183541,  0.00277786, -0.00507337,  0.00301519,\n",
      "       -0.00430553,  0.00191763, -0.0013001 , -0.00430087, -0.00219121,\n",
      "       -0.00098701,  0.00269658, -0.00368646, -0.0027277 ,  0.00523134,\n",
      "       -0.0020432 , -0.00102557, -0.00555117, -0.0031401 , -0.00684707,\n",
      "       -0.00135462, -0.00289208, -0.00450496, -0.00025816, -0.00333211,\n",
      "       -0.00707097,  0.00035207, -0.00548308,  0.00668492,  0.00026719,\n",
      "       -0.00100941, -0.00452871, -0.00076406, -0.0018825 ,  0.00448744,\n",
      "       -0.00400026, -0.00886064, -0.00357663,  0.00074361, -0.00304347,\n",
      "        0.0036677 , -0.00069436, -0.00565073,  0.00031492, -0.00022218,\n",
      "       -0.00525937,  0.00829425,  0.00081873,  0.00709243, -0.00042969,\n",
      "       -0.00092479,  0.00131073,  0.00330488,  0.00209675,  0.00297825,\n",
      "        0.00084639,  0.00418389,  0.00227102, -0.00327787, -0.00342379,\n",
      "       -0.00180731, -0.00227758, -0.0056736 , -0.0069665 , -0.00160248,\n",
      "       -0.00077844, -0.00084772, -0.00114325, -0.00324858, -0.00406844,\n",
      "       -0.00465104,  0.00477131, -0.00034302, -0.00281935, -0.00145886,\n",
      "        0.00324045, -0.00147891, -0.00302029, -0.00342179,  0.00089822,\n",
      "        0.00396991, -0.00442616, -0.00493821,  0.00108964, -0.00867751,\n",
      "        0.0070495 ,  0.00253998, -0.00288008, -0.00296132, -0.00630353,\n",
      "        0.0025006 , -0.00742584,  0.00029637,  0.00906392, -0.00356049,\n",
      "       -0.00022784,  0.00254983,  0.00038555,  0.00305321,  0.0009616 ,\n",
      "       -0.0012604 ,  0.00247838, -0.00493148, -0.00152249, -0.0057542 ,\n",
      "        0.00451849, -0.00127842,  0.00139242,  0.00237841, -0.01024266,\n",
      "        0.00301716, -0.00516601,  0.00139374, -0.00091123, -0.00354187,\n",
      "       -0.00394403, -0.0043123 , -0.00037044,  0.00058902, -0.00420657,\n",
      "        0.01231481, -0.00462543,  0.00118711, -0.00848093,  0.00244883,\n",
      "       -0.00210251, -0.00061992, -0.00323046,  0.00317382,  0.00206712,\n",
      "       -0.00252216, -0.0007276 , -0.00502334,  0.00044291,  0.00433636,\n",
      "       -0.00140512,  0.00102198, -0.00279379, -0.00872476, -0.00562474,\n",
      "       -0.00401852, -0.00131975, -0.0049375 ,  0.00735415,  0.00391081,\n",
      "        0.00582598, -0.00250438, -0.0029541 ,  0.00289129, -0.00861378,\n",
      "       -0.00488792, -0.00406279, -0.00011645,  0.0030637 , -0.00055305,\n",
      "       -0.00028203, -0.00469867, -0.00394149,  0.00394875,  0.00182308,\n",
      "        0.00018669, -0.00383426,  0.0021296 ,  0.00022929,  0.00141355,\n",
      "        0.00715296, -0.00000917,  0.00316249,  0.00224457,  0.00178132,\n",
      "        0.0045819 , -0.00354485, -0.00398301, -0.0078834 , -0.0034062 ,\n",
      "        0.00093998, -0.00872031, -0.00492191, -0.00360488, -0.00375913,\n",
      "       -0.0065353 , -0.00667834,  0.00124742,  0.00493561,  0.00045304,\n",
      "       -0.00106302,  0.00136701,  0.00132998, -0.00158193,  0.00155105,\n",
      "       -0.0047788 ,  0.00171734,  0.00312572,  0.00032646, -0.00525294,\n",
      "       -0.00151217,  0.00159565, -0.00218704, -0.00241459,  0.00059998,\n",
      "        0.0015426 , -0.00065278,  0.0082421 ,  0.00710663, -0.00320269,\n",
      "        0.00139299, -0.0007502 ,  0.00137424, -0.00653299, -0.00085381,\n",
      "        0.00024601, -0.00078383, -0.00730588, -0.00310968,  0.00452894,\n",
      "        0.00037332,  0.00178127,  0.00251092, -0.00582624, -0.00255102,\n",
      "       -0.00113128, -0.00768783,  0.00023827, -0.00432479, -0.00424795,\n",
      "        0.003082  ,  0.01041971], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weights_list = []\n",
    "for layer in model.layers[:45:3]:\n",
    "  layer_name = layer.name\n",
    "  # print(layer.name)\n",
    "  layer.set_weights(layer_dict[layer_name].get_weights())\n",
    "  print(layer.get_weights())\n",
    "  #print(type(np.asarray(layer.get_weights)))\n",
    "  x = (np.asarray(layer.get_weights()))\n",
    "\n",
    "  weights_list.append(np.asarray(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model2():\n",
    "    with tf.device(\"GPU:1\"):\n",
    "        nclass = 2\n",
    "        initializer1 = tf.keras.initializers.RandomNormal\n",
    "        initializer2 = tf.keras.initializers.Zeros()\n",
    "        initializer3 = tf.keras.initializers.glorot_uniform(seed=None)\n",
    "        initializer4 = tf.keras.initializers.lecun_normal(seed=None)\n",
    "        initializer5 = tf.keras.initializers.TruncatedNormal(mean=0., stddev=1.)\n",
    "\n",
    "        inp = Input(shape=cqt_input_shape)\n",
    "        img_1 = LeakyReLU(alpha=0.3)(inp)\n",
    "        img_1 = Conv2D(128, kernel_size=(7,7), \n",
    "                       # kernel_initializer=initializer4,  \n",
    "                       trainable = False,\n",
    "                       # kernel_regularizer = regularizers.l2(0.01),         \n",
    "                       #use_bias=True, \n",
    "                       #bias_initializer=initializers.Zeros(),\n",
    "                       padding=\"valid\")(img_1)\n",
    "        img_1 = Dropout(0.1)(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = MaxPooling2D()(img_1)\n",
    "        img_1 = Conv2D(128, kernel_size=(3,3),       \n",
    "                       # kernel_initializer=initializer4, \n",
    "                       trainable = False,\n",
    "                       # kernel_regularizer = regularizers.l2(0.01),            \n",
    "                       #use_bias=True, \n",
    "                       #bias_initializer=initializers.Zeros(),\n",
    "                       padding=\"valid\")(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = MaxPooling2D()(img_1)\n",
    "        img_1 = Dropout(0.1)(img_1)\n",
    "        img_1 = Conv2D(256, kernel_size=(3,3),       \n",
    "                       # kernel_initializer=initializer4, \n",
    "                       # kernel_regularizer = regularizers.l2(0.01), \n",
    "                       trainable = False,\n",
    "                       #use_bias=True, \n",
    "                       #bias_initializer=initializers.Zeros(),\n",
    "                       padding=\"valid\")(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.1)(img_1)   \n",
    "        img_1 = Flatten()(img_1)      \n",
    "        img_1 = Dense(512, \n",
    "                      # kernel_initializer=initializer4,  \n",
    "                      kernel_regularizer = regularizers.l2(0.001),\n",
    "                      # trainable = False,\n",
    "                     )(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.1)(img_1)   \n",
    "        \n",
    "        img_1 = Dense(128, kernel_initializer=initializer4, trainable = True,\n",
    "                             kernel_regularizer = regularizers.l2(0.001),\n",
    "                             use_bias=True, \n",
    "                             bias_initializer=initializer4,\n",
    "                            )(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.4)(img_1)   \n",
    "\n",
    "        img_1 = Dense(16, kernel_initializer=initializer4, trainable = True,\n",
    "                             kernel_regularizer = regularizers.l2(0.01),\n",
    "                             use_bias=True, \n",
    "                             bias_initializer=initializer4,\n",
    "                            )(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.5)(img_1)   \n",
    "\n",
    "\n",
    "        # 32 .3\n",
    "\n",
    "\n",
    "        output_layer = Dense(2,activation=activations.sigmoid)(img_1)\n",
    "        model = models.Model(inputs=[inp], outputs=[output_layer])\n",
    "        opt = optimizers.Adam(lr=0.00003, beta_1=0.9, beta_2=0.999, epsilon=1e-5, decay=.03, amsgrad=False)\n",
    "        model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before prediction\n",
    "K.clear_session()\n",
    "# from tensorflow.compat.v1 import ConfigProto\n",
    "# from tensorflow.compat.v1 import InteractiveSession\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "# # #session = InteractiveSession.close()\n",
    "# config = ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 70, 112, 1)]      0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 70, 112, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 106, 128)      6400      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 106, 128)      0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 106, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 30, 51, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 30, 51, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 23, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 13, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 76544)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               39191040  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 39,707,954\n",
      "Trainable params: 39,258,802\n",
      "Non-trainable params: 449,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_trained = get_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[ 0.20344156, -0.14032693,  0.00159053, ...,  0.13990973,\n",
      "          -0.21145575,  0.04415479]],\n",
      "\n",
      "        [[ 0.14212193, -0.10969139,  0.16181007, ..., -0.1959698 ,\n",
      "           0.00369271, -0.1389219 ]],\n",
      "\n",
      "        [[ 0.09005121, -0.03220682, -0.13282958, ...,  0.19589102,\n",
      "          -0.13432182,  0.03865555]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.12228387,  0.24794593, -0.17312826, ..., -0.00504658,\n",
      "          -0.11565565, -0.00908625]],\n",
      "\n",
      "        [[ 0.07937154, -0.17696281,  0.01539742, ...,  0.04942805,\n",
      "          -0.14245293, -0.14681588]],\n",
      "\n",
      "        [[ 0.08577465,  0.01018034,  0.03560253, ..., -0.08745713,\n",
      "          -0.10268371,  0.06127718]]],\n",
      "\n",
      "\n",
      "       [[[-0.24913326,  0.19086069, -0.06165431, ...,  0.01767287,\n",
      "          -0.10228569,  0.01031246]],\n",
      "\n",
      "        [[ 0.02302524, -0.17885692,  0.09230433, ...,  0.22210121,\n",
      "           0.21857555,  0.16122156]],\n",
      "\n",
      "        [[ 0.08564146,  0.07462309, -0.04462932, ..., -0.18619391,\n",
      "           0.00937441, -0.0192873 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.26078248, -0.07590015,  0.02379199, ...,  0.00960033,\n",
      "          -0.02356274, -0.00259919]],\n",
      "\n",
      "        [[ 0.08552652,  0.0416249 , -0.00074575, ...,  0.25064486,\n",
      "           0.0256728 ,  0.25268632]],\n",
      "\n",
      "        [[ 0.05929078,  0.09311096, -0.00317466, ...,  0.161062  ,\n",
      "          -0.06007414, -0.0433554 ]]],\n",
      "\n",
      "\n",
      "       [[[-0.03751412,  0.24350543,  0.09567795, ...,  0.05386169,\n",
      "          -0.02467597, -0.08831766]],\n",
      "\n",
      "        [[-0.14418143, -0.08760581,  0.03366129, ...,  0.05958871,\n",
      "           0.28025654, -0.15742575]],\n",
      "\n",
      "        [[ 0.00574811,  0.0846058 ,  0.13174032, ...,  0.13503398,\n",
      "          -0.22078736, -0.00821273]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.07646379,  0.04888817,  0.13899408, ...,  0.18815807,\n",
      "           0.01980291,  0.11520566]],\n",
      "\n",
      "        [[ 0.25651288,  0.00035931,  0.0880208 , ..., -0.15477017,\n",
      "          -0.06674456,  0.22481376]],\n",
      "\n",
      "        [[ 0.02682707, -0.020573  ,  0.0684669 , ..., -0.13558143,\n",
      "           0.07519905,  0.16513163]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[-0.02657963,  0.0614173 , -0.02878941, ..., -0.00504692,\n",
      "          -0.09039903,  0.02516118]],\n",
      "\n",
      "        [[-0.15271011, -0.03276251, -0.02224249, ..., -0.0849157 ,\n",
      "          -0.04029151, -0.08113581]],\n",
      "\n",
      "        [[ 0.21209887, -0.02845958,  0.1835108 , ..., -0.18086162,\n",
      "           0.15949817,  0.2346244 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.21255587, -0.15680166, -0.18975638, ...,  0.22812621,\n",
      "          -0.17389363, -0.01628027]],\n",
      "\n",
      "        [[-0.04710718, -0.02548954, -0.05939357, ...,  0.14593516,\n",
      "          -0.08844653,  0.04763095]],\n",
      "\n",
      "        [[-0.08110708,  0.09102746,  0.09500792, ...,  0.09578034,\n",
      "          -0.0389272 ,  0.17977831]]],\n",
      "\n",
      "\n",
      "       [[[-0.09302329,  0.02662711,  0.03411018, ...,  0.04020952,\n",
      "           0.08221621,  0.14262372]],\n",
      "\n",
      "        [[-0.03404611, -0.06344526, -0.04742213, ...,  0.06021897,\n",
      "           0.03664122, -0.1335036 ]],\n",
      "\n",
      "        [[-0.06106265, -0.17075603,  0.18812571, ...,  0.04905368,\n",
      "           0.0841461 , -0.05067836]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2444131 , -0.0565024 , -0.19146082, ..., -0.0472545 ,\n",
      "          -0.01628839, -0.0245533 ]],\n",
      "\n",
      "        [[ 0.05922221, -0.15880711, -0.11045432, ...,  0.1881911 ,\n",
      "          -0.07053788,  0.06068367]],\n",
      "\n",
      "        [[-0.07165845, -0.142423  , -0.06566931, ...,  0.05691656,\n",
      "          -0.18290627,  0.00118855]]],\n",
      "\n",
      "\n",
      "       [[[-0.01242649, -0.03148361, -0.02538076, ...,  0.00729751,\n",
      "           0.19120571, -0.03580773]],\n",
      "\n",
      "        [[-0.09263896,  0.01155842, -0.16817786, ...,  0.18835868,\n",
      "           0.0184942 ,  0.10774118]],\n",
      "\n",
      "        [[ 0.19380896,  0.08527803,  0.02751913, ..., -0.02565193,\n",
      "           0.2801542 , -0.05898971]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.19120589,  0.06544558, -0.02761444, ..., -0.12072548,\n",
      "           0.05525996,  0.00981625]],\n",
      "\n",
      "        [[-0.16913475, -0.07210259, -0.15425839, ...,  0.2076524 ,\n",
      "           0.06127165, -0.01650072]],\n",
      "\n",
      "        [[ 0.12102957, -0.01899148,  0.16071318, ...,  0.09983787,\n",
      "          -0.1164824 ,  0.24519703]]]], dtype=float32)\n",
      " array([-0.01184186, -0.00586363, -0.00441825, -0.00072963, -0.0063171 ,\n",
      "       -0.00462754, -0.00290536, -0.00317059, -0.00158698, -0.01099605,\n",
      "       -0.00556172, -0.00855327, -0.00324533, -0.00760504, -0.00635115,\n",
      "       -0.00322846, -0.00246117, -0.0053511 ,  0.00177987, -0.00827217,\n",
      "       -0.01124235, -0.0067934 , -0.00802746,  0.01058871, -0.00453459,\n",
      "       -0.00340058, -0.00734828, -0.00242486,  0.00168929, -0.01372272,\n",
      "       -0.01426456, -0.0021072 , -0.00290535,  0.00115954, -0.00583615,\n",
      "       -0.01140373,  0.01068615, -0.00683863, -0.01037524, -0.00319198,\n",
      "       -0.00522563, -0.00558602,  0.01472103, -0.00264176, -0.00631947,\n",
      "        0.00666949, -0.00484447, -0.00894226,  0.00870092,  0.01192288,\n",
      "        0.01182344, -0.01076312, -0.0110228 , -0.00031505, -0.00605306,\n",
      "       -0.00479986,  0.00338551, -0.0050567 ,  0.00045199, -0.00586111,\n",
      "       -0.00352604, -0.00551472, -0.00084059,  0.00393655, -0.00685421,\n",
      "        0.01092979,  0.00159785, -0.01059095, -0.00828071, -0.0129732 ,\n",
      "       -0.00580473,  0.00969892,  0.01137871, -0.00436235, -0.00409421,\n",
      "        0.00545692, -0.01214731, -0.01160362, -0.00515914, -0.00345264,\n",
      "       -0.00424096, -0.00693273, -0.00888213,  0.01300823, -0.00330948,\n",
      "       -0.00520293, -0.00253499,  0.00152751,  0.00859588, -0.00507127,\n",
      "       -0.00505858, -0.00776796, -0.00622455, -0.00698962, -0.00554625,\n",
      "       -0.00417055, -0.00280735,  0.00147817,  0.00636019, -0.00613487,\n",
      "       -0.00036257, -0.00457596,  0.00950514,  0.00765751, -0.0053661 ,\n",
      "       -0.00589761,  0.00326035,  0.01412401, -0.0073433 ,  0.01581927,\n",
      "       -0.00757439,  0.00859109, -0.01035162, -0.00661547, -0.01142599,\n",
      "        0.01074233, -0.00483829,  0.00242794, -0.00502466,  0.0008289 ,\n",
      "       -0.00259056, -0.00703122, -0.00878746,  0.00967421,  0.00194202,\n",
      "       -0.00891702,  0.01064773, -0.00566631], dtype=float32)]\n",
      "[array([[[[-0.01274797, -0.01750015, -0.0032456 , ...,  0.01181622,\n",
      "          -0.05759988,  0.00761262],\n",
      "         [ 0.00040183, -0.01549938, -0.00476371, ...,  0.01261942,\n",
      "           0.00787359,  0.00830912],\n",
      "         [ 0.00261837,  0.01287883, -0.00297042, ...,  0.01142274,\n",
      "           0.04355244, -0.00182737],\n",
      "         ...,\n",
      "         [-0.03145869, -0.03961362,  0.01442884, ..., -0.00159864,\n",
      "          -0.00571997, -0.00309643],\n",
      "         [-0.02546388,  0.02249187,  0.01070279, ...,  0.02995386,\n",
      "           0.00886253,  0.01235044],\n",
      "         [-0.0182313 ,  0.00215853,  0.00785278, ..., -0.02134913,\n",
      "          -0.00281625,  0.02463979]],\n",
      "\n",
      "        [[-0.06124048,  0.01429699, -0.00738343, ...,  0.03804845,\n",
      "          -0.06115933, -0.00475556],\n",
      "         [ 0.00996799, -0.0062937 ,  0.00105936, ..., -0.00928753,\n",
      "           0.01845692,  0.01483131],\n",
      "         [-0.01087578, -0.00290985, -0.00418177, ...,  0.01396103,\n",
      "          -0.03714573, -0.01887774],\n",
      "         ...,\n",
      "         [ 0.0180684 ,  0.01397017,  0.02801051, ..., -0.03895741,\n",
      "           0.05351716,  0.0097995 ],\n",
      "         [ 0.00888904,  0.02188873, -0.00974156, ..., -0.00610184,\n",
      "           0.02541162, -0.0006468 ],\n",
      "         [ 0.02872192, -0.01780498, -0.01769705, ..., -0.04237462,\n",
      "          -0.00438803,  0.00345325]],\n",
      "\n",
      "        [[-0.00516423, -0.01687338, -0.04394853, ..., -0.0555485 ,\n",
      "          -0.00656885,  0.02169844],\n",
      "         [-0.0002082 ,  0.01969809, -0.00255956, ..., -0.00751775,\n",
      "          -0.00858783,  0.01415546],\n",
      "         [ 0.00264176, -0.01817911,  0.01671539, ...,  0.00868129,\n",
      "           0.03075453,  0.02065412],\n",
      "         ...,\n",
      "         [ 0.00632122, -0.00507774, -0.01343305, ..., -0.00210487,\n",
      "           0.02343861, -0.00375096],\n",
      "         [-0.00648037,  0.0137033 , -0.01795595, ..., -0.00801437,\n",
      "           0.00921225, -0.01379761],\n",
      "         [ 0.01161742,  0.01303728, -0.02325365, ...,  0.00056841,\n",
      "          -0.02596469, -0.025501  ]]],\n",
      "\n",
      "\n",
      "       [[[-0.00363059, -0.00024769,  0.01573752, ..., -0.04785674,\n",
      "          -0.00057958,  0.02211987],\n",
      "         [ 0.00617106,  0.01082103, -0.00266103, ...,  0.00046016,\n",
      "           0.00038836, -0.01133615],\n",
      "         [ 0.00887624,  0.02153439, -0.02172367, ...,  0.01541358,\n",
      "          -0.00516073,  0.028558  ],\n",
      "         ...,\n",
      "         [ 0.01035905,  0.02898639, -0.02566892, ..., -0.00063234,\n",
      "          -0.00588884,  0.00339888],\n",
      "         [-0.00628206, -0.02919672,  0.04479545, ...,  0.00581085,\n",
      "          -0.04235919, -0.00273959],\n",
      "         [-0.0494056 , -0.0177444 ,  0.0148406 , ...,  0.00316794,\n",
      "          -0.00078548, -0.02151999]],\n",
      "\n",
      "        [[-0.02153806,  0.0063062 ,  0.0006391 , ...,  0.03972475,\n",
      "           0.02998287, -0.0224    ],\n",
      "         [-0.00338773, -0.00042008, -0.0033692 , ...,  0.01081082,\n",
      "          -0.01654826,  0.01141818],\n",
      "         [-0.00727325,  0.01007475, -0.00644845, ...,  0.03673575,\n",
      "          -0.02412429,  0.00758664],\n",
      "         ...,\n",
      "         [-0.01085681, -0.00277204, -0.00131565, ...,  0.02076685,\n",
      "           0.00786328, -0.00294742],\n",
      "         [-0.02729162, -0.03418817, -0.01860517, ..., -0.0351142 ,\n",
      "           0.00978605, -0.01800071],\n",
      "         [-0.03095551,  0.00817359, -0.03531276, ...,  0.00677547,\n",
      "          -0.03634617,  0.04383992]],\n",
      "\n",
      "        [[-0.00431247,  0.00658209,  0.02191735, ...,  0.02028335,\n",
      "           0.00751311,  0.0512724 ],\n",
      "         [ 0.00402835,  0.00440592, -0.00480916, ..., -0.00198062,\n",
      "          -0.00725212, -0.00461598],\n",
      "         [-0.0150673 ,  0.01196984, -0.0099953 , ...,  0.03433517,\n",
      "           0.02644688, -0.0095024 ],\n",
      "         ...,\n",
      "         [-0.02816083, -0.01096746, -0.00535576, ...,  0.03257636,\n",
      "          -0.05212878,  0.03623858],\n",
      "         [-0.00002544, -0.00430053,  0.03660965, ..., -0.01522879,\n",
      "           0.01598126, -0.00685334],\n",
      "         [ 0.00682523, -0.00434388,  0.00243612, ...,  0.00229311,\n",
      "          -0.00076917, -0.02397605]]],\n",
      "\n",
      "\n",
      "       [[[-0.00484692, -0.0112535 ,  0.02259467, ...,  0.0086323 ,\n",
      "          -0.0336018 ,  0.01530464],\n",
      "         [-0.00314373,  0.00991651, -0.0084624 , ...,  0.0083808 ,\n",
      "           0.01545734,  0.00878672],\n",
      "         [ 0.03204028,  0.00015342, -0.01640558, ..., -0.01586165,\n",
      "          -0.00749731,  0.00725044],\n",
      "         ...,\n",
      "         [ 0.04316982, -0.01965664, -0.0037473 , ..., -0.01878878,\n",
      "          -0.009258  , -0.0584103 ],\n",
      "         [-0.00336527,  0.00507983, -0.00354646, ..., -0.03320838,\n",
      "           0.01742508, -0.01997069],\n",
      "         [-0.02957176,  0.02148165, -0.00935626, ...,  0.00878335,\n",
      "          -0.02286259, -0.01102734]],\n",
      "\n",
      "        [[-0.02244416,  0.00923487, -0.01118695, ...,  0.00114257,\n",
      "          -0.01345445, -0.05689078],\n",
      "         [-0.01100239,  0.00297632,  0.01484041, ..., -0.00321202,\n",
      "           0.00831289,  0.00894937],\n",
      "         [-0.02219406,  0.00888297,  0.00422806, ...,  0.01757397,\n",
      "           0.0520511 , -0.01532975],\n",
      "         ...,\n",
      "         [-0.0366535 ,  0.00478877, -0.00981442, ..., -0.0150435 ,\n",
      "          -0.00784534,  0.01865866],\n",
      "         [ 0.01740092, -0.03601036,  0.00295167, ...,  0.02539971,\n",
      "          -0.02422122,  0.00206786],\n",
      "         [ 0.00663918,  0.03509028, -0.02627306, ...,  0.00781628,\n",
      "          -0.01092816,  0.00349464]],\n",
      "\n",
      "        [[-0.04631162, -0.00113952,  0.01862743, ..., -0.03848263,\n",
      "           0.03206592,  0.01184578],\n",
      "         [ 0.01563511,  0.00013858, -0.00628143, ..., -0.01112947,\n",
      "           0.01954475,  0.00212037],\n",
      "         [ 0.01580421,  0.02636129,  0.01567616, ...,  0.02780175,\n",
      "          -0.0203694 ,  0.00596   ],\n",
      "         ...,\n",
      "         [-0.05310017,  0.00070432, -0.03516881, ..., -0.01249749,\n",
      "          -0.02457319,  0.02199139],\n",
      "         [ 0.01002405,  0.00346395, -0.01289214, ...,  0.01834026,\n",
      "          -0.01905156, -0.0124191 ],\n",
      "         [-0.04405356, -0.0384289 , -0.02978036, ..., -0.00805799,\n",
      "          -0.0482161 , -0.03833145]]]], dtype=float32)\n",
      " array([-0.00306164, -0.00576156,  0.007366  ,  0.00321478, -0.00644378,\n",
      "       -0.00308059, -0.00040366,  0.00485817,  0.00333193, -0.00700917,\n",
      "        0.00199252,  0.00603514, -0.00233024, -0.00473583, -0.00084202,\n",
      "       -0.00209414, -0.00661831, -0.00028531,  0.00347731, -0.00356151,\n",
      "        0.00535273, -0.00281878, -0.00089036,  0.00003238, -0.00092186,\n",
      "        0.0035637 ,  0.00348046, -0.0105194 ,  0.00298797, -0.00514438,\n",
      "       -0.0040685 ,  0.00530917, -0.00444542, -0.00270197, -0.00357264,\n",
      "        0.01147601, -0.00760202, -0.00326306, -0.00473563, -0.00420615,\n",
      "       -0.00609886,  0.00319507, -0.00136048, -0.00439961, -0.00060016,\n",
      "        0.00031584, -0.00804651, -0.00437042, -0.00770577, -0.00415567,\n",
      "       -0.00422402, -0.00224054,  0.00503499, -0.00282136, -0.0032802 ,\n",
      "       -0.00499098, -0.00277185,  0.00433243, -0.00621941, -0.0046043 ,\n",
      "       -0.00453065, -0.00267569, -0.00820656, -0.00324686, -0.00424899,\n",
      "        0.0014116 ,  0.00703068, -0.00807001,  0.00181567,  0.00548703,\n",
      "       -0.00474211, -0.00384198,  0.00672869, -0.00237795, -0.00190049,\n",
      "       -0.00311683, -0.00442817,  0.00015611, -0.00295496, -0.0031635 ,\n",
      "       -0.00624232,  0.00256306, -0.00246772,  0.00151161, -0.00460515,\n",
      "        0.00258101, -0.00110136,  0.0068256 , -0.00592917, -0.00120585,\n",
      "        0.00478824,  0.00332032, -0.00378385,  0.00053347, -0.00155724,\n",
      "       -0.00265623, -0.00144203,  0.00146642, -0.00252123,  0.00022099,\n",
      "       -0.00025869, -0.00306109,  0.0014316 ,  0.00477344,  0.00619777,\n",
      "       -0.005019  , -0.00350258,  0.00369648, -0.00442714, -0.00617525,\n",
      "       -0.00085998, -0.00226144, -0.00590206, -0.00114266, -0.00749706,\n",
      "       -0.00529076, -0.00232912, -0.00164042, -0.0007293 , -0.00099945,\n",
      "       -0.0034707 ,  0.00087797, -0.00530855, -0.00365602, -0.00366722,\n",
      "       -0.00556434, -0.0010296 , -0.00163304], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[[ 0.00513944,  0.00474862,  0.01245621, ...,  0.00763899,\n",
      "           0.01000646, -0.00038219],\n",
      "         [-0.00184024, -0.00986486,  0.01281886, ...,  0.01952427,\n",
      "           0.0108036 , -0.00762373],\n",
      "         [ 0.00771981, -0.00473628, -0.0175372 , ..., -0.00445185,\n",
      "          -0.01025867, -0.01352853],\n",
      "         ...,\n",
      "         [-0.01458863, -0.01428088, -0.00522701, ..., -0.01526715,\n",
      "          -0.00844157, -0.00252435],\n",
      "         [-0.00645196,  0.02031715, -0.0066627 , ..., -0.02447101,\n",
      "           0.04493306, -0.0007815 ],\n",
      "         [ 0.00089813, -0.02656673,  0.01490098, ...,  0.011683  ,\n",
      "          -0.01231718,  0.0095048 ]],\n",
      "\n",
      "        [[-0.01677419,  0.0208605 ,  0.01219983, ...,  0.00718892,\n",
      "          -0.00313994,  0.00678297],\n",
      "         [ 0.02544815, -0.00732442, -0.00506847, ...,  0.02711425,\n",
      "          -0.01220124,  0.01452733],\n",
      "         [ 0.01427806, -0.01392645,  0.00802844, ..., -0.01712665,\n",
      "          -0.00281863,  0.00790989],\n",
      "         ...,\n",
      "         [ 0.03212005,  0.0057919 , -0.00544708, ..., -0.00386123,\n",
      "           0.00554811, -0.00056994],\n",
      "         [ 0.00080624,  0.02028387, -0.00137709, ...,  0.01646182,\n",
      "           0.00839177, -0.00283599],\n",
      "         [-0.00961311, -0.00901578, -0.02718079, ...,  0.00872803,\n",
      "           0.0075837 ,  0.01733745]],\n",
      "\n",
      "        [[ 0.00168204,  0.01066619, -0.00162843, ..., -0.00932381,\n",
      "          -0.04832532, -0.00499728],\n",
      "         [-0.00016956, -0.01855702,  0.01018711, ...,  0.00053558,\n",
      "           0.03311992, -0.02923566],\n",
      "         [-0.00184368, -0.00083924, -0.00952217, ..., -0.00669232,\n",
      "          -0.02817638, -0.01243479],\n",
      "         ...,\n",
      "         [-0.03121135,  0.02568243,  0.02290506, ...,  0.02061877,\n",
      "           0.03711049, -0.01032914],\n",
      "         [ 0.01594144,  0.02906961, -0.01271119, ...,  0.00416776,\n",
      "           0.01608404, -0.00069296],\n",
      "         [-0.01191951, -0.02748825, -0.00430417, ...,  0.00340858,\n",
      "           0.04318714, -0.01726716]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00389849,  0.0024286 , -0.00836344, ...,  0.01504809,\n",
      "          -0.00879572, -0.00027397],\n",
      "         [-0.01253392, -0.02240382,  0.01582664, ...,  0.01756765,\n",
      "           0.01083644, -0.00833022],\n",
      "         [-0.01480757,  0.00240704, -0.00569121, ..., -0.01472915,\n",
      "           0.00014521, -0.00937514],\n",
      "         ...,\n",
      "         [ 0.01633546, -0.01673839, -0.01891181, ..., -0.0020788 ,\n",
      "           0.02580629,  0.00457958],\n",
      "         [-0.01143092, -0.00507169,  0.01496571, ...,  0.02448428,\n",
      "           0.01486244,  0.00163586],\n",
      "         [ 0.01677752, -0.01043794, -0.00919564, ...,  0.00733722,\n",
      "          -0.00926878, -0.01036367]],\n",
      "\n",
      "        [[ 0.01062923,  0.02879336,  0.02741277, ..., -0.03062893,\n",
      "          -0.02945767, -0.00090868],\n",
      "         [ 0.01957755,  0.00512588,  0.02033887, ..., -0.00311459,\n",
      "          -0.00953576, -0.00186873],\n",
      "         [ 0.00565871,  0.00237276,  0.00359628, ..., -0.02091851,\n",
      "           0.00691655, -0.00449812],\n",
      "         ...,\n",
      "         [-0.03442284, -0.00715162, -0.00882654, ..., -0.01508338,\n",
      "          -0.0316854 , -0.02161299],\n",
      "         [ 0.00548226,  0.02040372,  0.03142112, ...,  0.00012052,\n",
      "           0.00411727, -0.01309154],\n",
      "         [ 0.03181156, -0.01483589, -0.02153408, ..., -0.0065103 ,\n",
      "           0.00146925, -0.03288825]],\n",
      "\n",
      "        [[ 0.00289304,  0.02038513, -0.00216593, ..., -0.00850859,\n",
      "           0.02256988,  0.00471273],\n",
      "         [ 0.00045701,  0.02119216,  0.01178503, ...,  0.01786671,\n",
      "           0.04131975, -0.00596333],\n",
      "         [ 0.01447233, -0.01445081, -0.00946809, ..., -0.00452775,\n",
      "          -0.00572341, -0.01029969],\n",
      "         ...,\n",
      "         [-0.00292314, -0.03187469,  0.01564691, ..., -0.01467776,\n",
      "          -0.02207987,  0.0048373 ],\n",
      "         [-0.00008177,  0.02568494, -0.01002193, ..., -0.01461998,\n",
      "           0.00318485, -0.00594681],\n",
      "         [ 0.00877565,  0.01976676, -0.02067527, ...,  0.01327044,\n",
      "           0.00622752,  0.0185409 ]]],\n",
      "\n",
      "\n",
      "       [[[ 0.00181949, -0.02846053, -0.02533901, ..., -0.0073945 ,\n",
      "           0.01252352, -0.00570648],\n",
      "         [-0.00000796,  0.01210331, -0.00381262, ...,  0.03223961,\n",
      "           0.00222726, -0.0028999 ],\n",
      "         [ 0.01164998,  0.01078254, -0.00169917, ...,  0.00173886,\n",
      "           0.00367215,  0.00993069],\n",
      "         ...,\n",
      "         [-0.01544315, -0.04173438,  0.00013238, ...,  0.00775253,\n",
      "          -0.00862544, -0.01034079],\n",
      "         [-0.02767782,  0.02820301, -0.00438418, ..., -0.00128391,\n",
      "          -0.02107836, -0.00336776],\n",
      "         [-0.00940552, -0.02217955, -0.01114647, ...,  0.00673708,\n",
      "           0.02805669, -0.00528261]],\n",
      "\n",
      "        [[-0.00581369,  0.01821237, -0.03226506, ...,  0.00345775,\n",
      "          -0.01450897,  0.00083506],\n",
      "         [-0.00484255,  0.01706507,  0.00478831, ...,  0.00954173,\n",
      "           0.01355653, -0.00705965],\n",
      "         [-0.01263062,  0.01300108, -0.0072763 , ..., -0.01318857,\n",
      "          -0.00932285,  0.00296462],\n",
      "         ...,\n",
      "         [-0.00502571,  0.02195894, -0.01438368, ...,  0.0142226 ,\n",
      "           0.02247941, -0.00083751],\n",
      "         [-0.02885487,  0.00744063,  0.03803311, ...,  0.00108315,\n",
      "           0.01930644, -0.02334579],\n",
      "         [-0.02833097, -0.01553523,  0.0099165 , ..., -0.01971315,\n",
      "          -0.01579149, -0.01935586]],\n",
      "\n",
      "        [[-0.00015441, -0.0225389 ,  0.03003269, ...,  0.00243888,\n",
      "          -0.01977463, -0.00092836],\n",
      "         [-0.01208753,  0.00667654, -0.00019716, ..., -0.00643728,\n",
      "          -0.03086523,  0.00819908],\n",
      "         [-0.00876451, -0.02833416,  0.00437406, ..., -0.00359948,\n",
      "           0.00330776, -0.0121947 ],\n",
      "         ...,\n",
      "         [-0.01110719,  0.03768598,  0.00244523, ..., -0.0102061 ,\n",
      "          -0.00963468, -0.00702629],\n",
      "         [-0.00514251, -0.00094167,  0.02342214, ...,  0.01002803,\n",
      "          -0.00396938, -0.02711187],\n",
      "         [ 0.00568984,  0.00172438, -0.01818582, ...,  0.00330175,\n",
      "          -0.0155292 ,  0.01169714]]]], dtype=float32)\n",
      " array([ 0.00048081,  0.00537341, -0.01023656, -0.01134442, -0.00716715,\n",
      "       -0.0039416 , -0.00126232, -0.00492089, -0.00583098,  0.01178973,\n",
      "       -0.00382337, -0.00258729, -0.00203323, -0.00052483,  0.00150324,\n",
      "       -0.00668608, -0.00296489, -0.00792054,  0.00471704,  0.00226781,\n",
      "       -0.00316878, -0.01112941, -0.00265454, -0.00295056,  0.00001239,\n",
      "        0.01103003, -0.00094282,  0.00868378, -0.00791644,  0.00302579,\n",
      "       -0.00384986, -0.00684783,  0.01093984, -0.00290191, -0.00113589,\n",
      "       -0.00361749, -0.00032049, -0.00141583, -0.00389159,  0.00920379,\n",
      "       -0.00432913, -0.00212995,  0.00273429, -0.00122719, -0.00489612,\n",
      "       -0.00389642, -0.00406348, -0.00712021, -0.00498956, -0.00102453,\n",
      "       -0.00815793, -0.00606457,  0.00160131, -0.00053656, -0.00435127,\n",
      "        0.00864308, -0.0077472 ,  0.00648263, -0.00232242,  0.00470562,\n",
      "       -0.00521394, -0.00195845, -0.00102674,  0.00382181, -0.00408394,\n",
      "       -0.00008063,  0.00463972, -0.00400941, -0.00473272, -0.00211752,\n",
      "       -0.00896064, -0.00681279, -0.00162539, -0.00064053, -0.0029947 ,\n",
      "       -0.0023552 , -0.0095288 ,  0.00047913, -0.00521292, -0.00303649,\n",
      "       -0.00040601, -0.00395279, -0.00228127, -0.00060155, -0.00254836,\n",
      "       -0.01089551, -0.0035598 , -0.00035154, -0.00506322, -0.00846649,\n",
      "        0.00139742,  0.00277809, -0.00468147,  0.0004045 , -0.00843775,\n",
      "       -0.00209849, -0.00557934,  0.00245239,  0.00421613, -0.00615768,\n",
      "       -0.0053247 , -0.01084067, -0.00003819, -0.00415875, -0.00843744,\n",
      "       -0.00788816, -0.0014288 , -0.00335097, -0.00431868, -0.01004049,\n",
      "       -0.00673613, -0.00466269,  0.00266931, -0.00145483, -0.00516897,\n",
      "        0.00013786,  0.00057077, -0.00335247, -0.00308134, -0.00304023,\n",
      "       -0.00892951, -0.00315647, -0.00186062, -0.00377925, -0.00879415,\n",
      "       -0.00255027,  0.00370152, -0.00728933, -0.00583923, -0.00099579,\n",
      "       -0.0014751 , -0.0068173 ,  0.00172303, -0.01089846, -0.00025948,\n",
      "       -0.00554349, -0.00225573, -0.00646746, -0.00316585, -0.00443153,\n",
      "       -0.00096428,  0.00064699, -0.00519814,  0.00316633,  0.00043454,\n",
      "       -0.00242603, -0.00946059, -0.00535921, -0.00381016,  0.00575343,\n",
      "       -0.00513926, -0.00299249, -0.00742627, -0.00432381, -0.00008176,\n",
      "       -0.00189748, -0.00799832,  0.00137489, -0.00598274, -0.00709902,\n",
      "       -0.00176367, -0.00170524, -0.0041715 , -0.00685914,  0.00094967,\n",
      "        0.00074564, -0.00191951, -0.00164296,  0.00229138, -0.00661315,\n",
      "        0.00062204, -0.00376234,  0.00471801, -0.00430114, -0.00060248,\n",
      "       -0.00593714,  0.00269601, -0.00477198, -0.0060945 , -0.00291949,\n",
      "       -0.00867288, -0.0028812 ,  0.00377955, -0.00737539, -0.00457996,\n",
      "       -0.0063464 , -0.00426022, -0.00208927,  0.0030305 , -0.00356407,\n",
      "       -0.00297688, -0.00100073, -0.00060814, -0.00301404, -0.00434705,\n",
      "        0.00204731, -0.00651242, -0.00350051,  0.00848872, -0.00870485,\n",
      "       -0.00770562, -0.00285125, -0.00755032, -0.00078687, -0.0075463 ,\n",
      "       -0.00121259,  0.00296231, -0.00316442, -0.0051225 , -0.00019626,\n",
      "        0.00140216, -0.00159993,  0.00319415, -0.00233976, -0.00166348,\n",
      "        0.00390642, -0.00607883, -0.01342907,  0.00042415,  0.00118824,\n",
      "       -0.0037047 , -0.00338233, -0.00533131, -0.00564032, -0.00377695,\n",
      "        0.00143163, -0.0027647 ,  0.00139797, -0.00100255, -0.00532046,\n",
      "       -0.00391973, -0.00532035, -0.00585625,  0.00116528, -0.00528429,\n",
      "       -0.0065658 , -0.00422714,  0.00047859,  0.00408836,  0.00354554,\n",
      "       -0.00621302, -0.00180784, -0.00884719, -0.00578615, -0.00007808,\n",
      "       -0.00485476, -0.00028153,  0.00096382, -0.0039189 , -0.00087327,\n",
      "        0.00660498, -0.00421824, -0.00000114, -0.00264787, -0.00767985,\n",
      "        0.00162106], dtype=float32)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.00033332,  0.00057715,  0.00128879, ..., -0.00047167,\n",
      "        -0.00003207,  0.00010454],\n",
      "       [-0.00181719,  0.00587172,  0.00047248, ...,  0.00022697,\n",
      "         0.00037298, -0.00334244],\n",
      "       [ 0.00037552,  0.00004229,  0.00112876, ..., -0.00110811,\n",
      "         0.00069491,  0.00223617],\n",
      "       ...,\n",
      "       [ 0.00009202,  0.00214761,  0.00044192, ..., -0.00063407,\n",
      "         0.00036445, -0.00075378],\n",
      "       [-0.00064835,  0.00159977,  0.00134262, ..., -0.00050995,\n",
      "        -0.0002528 , -0.00016015],\n",
      "       [-0.00103454,  0.00084928,  0.00080043, ..., -0.00096654,\n",
      "        -0.00014226, -0.00068665]], dtype=float32)\n",
      " array([ 0.00008462,  0.00138961,  0.00336087,  0.00485914,  0.00031483,\n",
      "        0.0049026 , -0.00117229,  0.00368856, -0.00623961, -0.00137114,\n",
      "        0.00037027,  0.00627798, -0.00338869, -0.00082213, -0.00145492,\n",
      "        0.00026201,  0.00889966, -0.0005831 ,  0.00013409,  0.00226381,\n",
      "        0.00022172, -0.00050769,  0.00469144,  0.00602235, -0.00385617,\n",
      "       -0.00786847, -0.0060908 , -0.00241105, -0.00262061,  0.00174839,\n",
      "       -0.0024485 ,  0.00003705,  0.00406626, -0.00115189, -0.00461034,\n",
      "        0.00175073, -0.00604972,  0.00134371,  0.00115691, -0.00243375,\n",
      "       -0.00047227, -0.0069081 ,  0.00185645, -0.0039479 , -0.00437266,\n",
      "        0.00165777, -0.00383107,  0.0024096 ,  0.00174912, -0.00810387,\n",
      "        0.00616293, -0.00602621, -0.00825927, -0.00138768, -0.00120958,\n",
      "       -0.00402852, -0.00550189, -0.00198014, -0.00260874, -0.00426532,\n",
      "       -0.00216752, -0.00344   , -0.00020756, -0.00835074,  0.00920823,\n",
      "       -0.00249562, -0.00226509, -0.00840797, -0.00531015,  0.0008148 ,\n",
      "       -0.00429755,  0.00106193,  0.00280644,  0.00409106, -0.00155608,\n",
      "        0.00020072, -0.00295753, -0.0053336 , -0.00385303,  0.00198172,\n",
      "       -0.00581853, -0.00082322, -0.00203008, -0.00783883, -0.00196176,\n",
      "        0.00182848, -0.00114064,  0.00850722,  0.00363854,  0.00430962,\n",
      "        0.00204001,  0.00782901,  0.00314076, -0.0034844 , -0.00239958,\n",
      "       -0.00001564, -0.00422917,  0.00143823,  0.00044749, -0.00164727,\n",
      "        0.00318454,  0.00583898,  0.00154922, -0.00717773, -0.00679087,\n",
      "       -0.00067519,  0.00657372, -0.0109893 ,  0.00273107,  0.00089574,\n",
      "       -0.00694649,  0.00212861,  0.00052593,  0.00640735, -0.00186347,\n",
      "        0.00437842, -0.00486254, -0.00348664, -0.00190438,  0.00133381,\n",
      "        0.00253595, -0.00411459, -0.00185324, -0.00390084, -0.00883487,\n",
      "       -0.00626175, -0.00027894,  0.0027657 ,  0.00667   , -0.00574503,\n",
      "       -0.00030581, -0.00698628, -0.00184246, -0.00674305, -0.0023588 ,\n",
      "       -0.0001746 , -0.0034966 , -0.00327384, -0.00789529, -0.00816816,\n",
      "       -0.00745546, -0.00067474, -0.00800721,  0.00404498, -0.00663209,\n",
      "       -0.00296666,  0.00424886,  0.00645763,  0.00727579, -0.00563184,\n",
      "       -0.00280505,  0.00037214, -0.00517979,  0.00296123,  0.00233822,\n",
      "       -0.00179594,  0.0000448 ,  0.00468258,  0.00520241,  0.00189351,\n",
      "       -0.00252578, -0.00016238, -0.00325185, -0.00169704, -0.00377579,\n",
      "        0.00786639, -0.00482275, -0.00017727,  0.00082191, -0.00168281,\n",
      "       -0.00395621, -0.00248065,  0.00026508, -0.00235496, -0.00321353,\n",
      "       -0.00135077, -0.00143825,  0.00079955, -0.0075908 , -0.00446301,\n",
      "       -0.00049985, -0.00614863, -0.00542739, -0.00270519, -0.00335065,\n",
      "       -0.00083248,  0.00074645, -0.0017318 ,  0.00398066,  0.00061564,\n",
      "        0.00441656,  0.00435304,  0.00062087, -0.00056325, -0.00205577,\n",
      "        0.00016484, -0.00505497, -0.00362435, -0.00452524, -0.0043274 ,\n",
      "       -0.00012787, -0.00266806, -0.00976194,  0.00779702, -0.00122403,\n",
      "        0.0029793 , -0.00293208, -0.00553666,  0.00048366,  0.00607285,\n",
      "        0.00078684,  0.0063473 , -0.00661713,  0.00115981,  0.00562643,\n",
      "       -0.00565752, -0.00571291, -0.00187033, -0.00635097, -0.00317004,\n",
      "       -0.00936158,  0.00082457, -0.00106221, -0.00570754,  0.00136766,\n",
      "       -0.00468263, -0.00096305, -0.00753175,  0.00032006,  0.00149649,\n",
      "       -0.00063426,  0.00406983, -0.00036815, -0.00376419, -0.00326924,\n",
      "        0.00068032, -0.00192211, -0.00250183, -0.00076733, -0.00926673,\n",
      "       -0.003518  ,  0.00739206,  0.00388452, -0.00109787, -0.00124986,\n",
      "        0.00031669,  0.00461557,  0.00562311,  0.0051491 , -0.00403313,\n",
      "       -0.00491251, -0.00643839,  0.00024606,  0.00158038,  0.00297537,\n",
      "       -0.00029382,  0.00242595, -0.00721128, -0.00283652,  0.00038211,\n",
      "       -0.00312136, -0.00486969, -0.0070395 , -0.00157557,  0.00232329,\n",
      "        0.00054038,  0.00182219,  0.00649905, -0.00227603, -0.0005688 ,\n",
      "       -0.00963596,  0.00086047,  0.00152044,  0.00247945, -0.00343253,\n",
      "       -0.00651166,  0.00748552,  0.01017263,  0.00202908,  0.00341217,\n",
      "       -0.00546844,  0.00258795,  0.00211147,  0.00467079,  0.004119  ,\n",
      "        0.00154661, -0.00183541,  0.00277786, -0.00507337,  0.00301519,\n",
      "       -0.00430553,  0.00191763, -0.0013001 , -0.00430087, -0.00219121,\n",
      "       -0.00098701,  0.00269658, -0.00368646, -0.0027277 ,  0.00523134,\n",
      "       -0.0020432 , -0.00102557, -0.00555117, -0.0031401 , -0.00684707,\n",
      "       -0.00135462, -0.00289208, -0.00450496, -0.00025816, -0.00333211,\n",
      "       -0.00707097,  0.00035207, -0.00548308,  0.00668492,  0.00026719,\n",
      "       -0.00100941, -0.00452871, -0.00076406, -0.0018825 ,  0.00448744,\n",
      "       -0.00400026, -0.00886064, -0.00357663,  0.00074361, -0.00304347,\n",
      "        0.0036677 , -0.00069436, -0.00565073,  0.00031492, -0.00022218,\n",
      "       -0.00525937,  0.00829425,  0.00081873,  0.00709243, -0.00042969,\n",
      "       -0.00092479,  0.00131073,  0.00330488,  0.00209675,  0.00297825,\n",
      "        0.00084639,  0.00418389,  0.00227102, -0.00327787, -0.00342379,\n",
      "       -0.00180731, -0.00227758, -0.0056736 , -0.0069665 , -0.00160248,\n",
      "       -0.00077844, -0.00084772, -0.00114325, -0.00324858, -0.00406844,\n",
      "       -0.00465104,  0.00477131, -0.00034302, -0.00281935, -0.00145886,\n",
      "        0.00324045, -0.00147891, -0.00302029, -0.00342179,  0.00089822,\n",
      "        0.00396991, -0.00442616, -0.00493821,  0.00108964, -0.00867751,\n",
      "        0.0070495 ,  0.00253998, -0.00288008, -0.00296132, -0.00630353,\n",
      "        0.0025006 , -0.00742584,  0.00029637,  0.00906392, -0.00356049,\n",
      "       -0.00022784,  0.00254983,  0.00038555,  0.00305321,  0.0009616 ,\n",
      "       -0.0012604 ,  0.00247838, -0.00493148, -0.00152249, -0.0057542 ,\n",
      "        0.00451849, -0.00127842,  0.00139242,  0.00237841, -0.01024266,\n",
      "        0.00301716, -0.00516601,  0.00139374, -0.00091123, -0.00354187,\n",
      "       -0.00394403, -0.0043123 , -0.00037044,  0.00058902, -0.00420657,\n",
      "        0.01231481, -0.00462543,  0.00118711, -0.00848093,  0.00244883,\n",
      "       -0.00210251, -0.00061992, -0.00323046,  0.00317382,  0.00206712,\n",
      "       -0.00252216, -0.0007276 , -0.00502334,  0.00044291,  0.00433636,\n",
      "       -0.00140512,  0.00102198, -0.00279379, -0.00872476, -0.00562474,\n",
      "       -0.00401852, -0.00131975, -0.0049375 ,  0.00735415,  0.00391081,\n",
      "        0.00582598, -0.00250438, -0.0029541 ,  0.00289129, -0.00861378,\n",
      "       -0.00488792, -0.00406279, -0.00011645,  0.0030637 , -0.00055305,\n",
      "       -0.00028203, -0.00469867, -0.00394149,  0.00394875,  0.00182308,\n",
      "        0.00018669, -0.00383426,  0.0021296 ,  0.00022929,  0.00141355,\n",
      "        0.00715296, -0.00000917,  0.00316249,  0.00224457,  0.00178132,\n",
      "        0.0045819 , -0.00354485, -0.00398301, -0.0078834 , -0.0034062 ,\n",
      "        0.00093998, -0.00872031, -0.00492191, -0.00360488, -0.00375913,\n",
      "       -0.0065353 , -0.00667834,  0.00124742,  0.00493561,  0.00045304,\n",
      "       -0.00106302,  0.00136701,  0.00132998, -0.00158193,  0.00155105,\n",
      "       -0.0047788 ,  0.00171734,  0.00312572,  0.00032646, -0.00525294,\n",
      "       -0.00151217,  0.00159565, -0.00218704, -0.00241459,  0.00059998,\n",
      "        0.0015426 , -0.00065278,  0.0082421 ,  0.00710663, -0.00320269,\n",
      "        0.00139299, -0.0007502 ,  0.00137424, -0.00653299, -0.00085381,\n",
      "        0.00024601, -0.00078383, -0.00730588, -0.00310968,  0.00452894,\n",
      "        0.00037332,  0.00178127,  0.00251092, -0.00582624, -0.00255102,\n",
      "       -0.00113128, -0.00768783,  0.00023827, -0.00432479, -0.00424795,\n",
      "        0.003082  ,  0.01041971], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "indexlayers = [2,6,10,14]\n",
    "for layerweight in indexlayers:\n",
    "\n",
    "    pre_trained.layers[layerweight].set_weights(weights_list[layerweight])   \n",
    "    print(weights_list[layerweight])\n",
    "\n",
    "\n",
    "for indexlayer in indexlayers:    \n",
    "    layer = pre_trained.layers[indexlayer]\n",
    "    layer.trainable =  False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds/ferry-data/ferry-cqt'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ferry Data Inputs\n",
    "Pre-proceseed, mapped to same sample rate, transformed to cqt and unrolled into a 2D matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/pattyry/birds/ferry-data/ferry-cqt'"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(birds_home)\n",
    "cwd_ferry_audio = os.path.join(\"./ferry-data\",\"ferry-cqt\")\n",
    "os.chdir(cwd_ferry_audio)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 1)\n",
      "(66, 1)\n"
     ]
    }
   ],
   "source": [
    "cqt_y_train =pd.read_csv('y_train.csv', sep=',',header=None)\n",
    "print(cqt_y_train.shape)\n",
    "cqt_y_train = np.asarray(cqt_y_train)\n",
    "\n",
    "cqt_y_test =pd.read_csv('y_test.csv', sep=',',header=None)\n",
    "print(cqt_y_test.shape)\n",
    "cqt_y_test = np.asarray(cqt_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 7840)\n"
     ]
    }
   ],
   "source": [
    "cqt_x_test =pd.read_csv('x_test.csv', sep=',',header=None)\n",
    "print(cqt_x_test.shape)\n",
    "cqt_x_test = np.asarray(cqt_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 7840)\n"
     ]
    }
   ],
   "source": [
    "cqt_x_train =pd.read_csv('x_train.csv', sep=',',header=None)\n",
    "print(cqt_x_train.shape)\n",
    "cqt_x_train = np.asarray(cqt_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "167\n",
      "70\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "#Define Single input shape\n",
    "num_test_samples = cqt_x_test.shape[0]\n",
    "num_train_samples = cqt_x_train.shape[0]\n",
    "num_timesteps = 70\n",
    "num_features = 112\n",
    "print(num_test_samples)\n",
    "print(num_train_samples)\n",
    "print(num_timesteps)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt_x_test = np.array(cqt_x_test).reshape(num_test_samples, num_timesteps, num_features, 1)\n",
    "cqt_x_train = np.array(cqt_x_train).reshape(num_train_samples, num_timesteps, num_features, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "cqt_x_test = np.float32(cqt_x_test)\n",
    "cqt_x_train = np.float32(cqt_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 70, 112, 1)\n",
      "(167, 70, 112, 1)\n",
      "(66, 1)\n",
      "(167, 1)\n"
     ]
    }
   ],
   "source": [
    "print(cqt_x_test.shape)\n",
    "print(cqt_x_train.shape)\n",
    "\n",
    "print(cqt_y_test.shape)\n",
    "print(cqt_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If wanted, add class weighting\n",
    "total_len = len(cqt_y_train)\n",
    "class_weight = {0: total_len/len([x for x in cqt_y_train==0 if x]),\n",
    "                1: total_len/len([x for x in cqt_y_train==1 if x])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_layer = 14\n",
    "\n",
    "for layer in pre_trained.layers[:from_layer]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_save_ = ModelCheckpoint('spec_augment_only_ferry_pretrained_6-14.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                  factor=.1, \n",
    "                                  patience=1, \n",
    "                                  verbose=0, \n",
    "                                  mode='auto', \n",
    "                                  min_delta=0.00001, \n",
    "                                  cooldown=0, \n",
    "                                  min_lr=0)\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 167 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 8s 48ms/sample - loss: 110771.6005 - acc: 0.5090 - val_loss: 9472.7562 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 4s 22ms/sample - loss: 66018.7053 - acc: 0.4731 - val_loss: 6010.1399 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - 7s 43ms/sample - loss: 47384.5803 - acc: 0.5000 - val_loss: 3351.1176 - val_acc: 0.5682\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - 4s 23ms/sample - loss: 36668.9863 - acc: 0.4940 - val_loss: 4411.1394 - val_acc: 0.5000\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - 4s 23ms/sample - loss: 27070.6848 - acc: 0.5359 - val_loss: 4318.3254 - val_acc: 0.5076\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - 4s 23ms/sample - loss: 22092.6531 - acc: 0.6138 - val_loss: 4278.3776 - val_acc: 0.5076\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - 4s 23ms/sample - loss: 30729.5299 - acc: 0.5180 - val_loss: 4273.8599 - val_acc: 0.5076\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - 4s 25ms/sample - loss: 30631.3321 - acc: 0.5599 - val_loss: 4273.5064 - val_acc: 0.5076\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - 4s 22ms/sample - loss: 30301.1111 - acc: 0.5359 - val_loss: 4273.4978 - val_acc: 0.5076\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - 4s 23ms/sample - loss: 29683.6111 - acc: 0.5030 - val_loss: 4273.4973 - val_acc: 0.5076\n"
     ]
    }
   ],
   "source": [
    "history = pre_trained.fit([cqt_x_train],[to_categorical(cqt_y_train)], \n",
    "                         epochs=10, \n",
    "                         batch_size=8,\n",
    "                         validation_data=([cqt_x_test], to_categorical(cqt_y_test)),\n",
    "                         callbacks=[mcp_save_, reduce_lr],\n",
    "                         class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Without pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model3():\n",
    "    with tf.device(\"GPU:1\"):\n",
    "        nclass = 2\n",
    "        initializer1 = tf.keras.initializers.RandomNormal\n",
    "        initializer2 = tf.keras.initializers.Zeros()\n",
    "        initializer3 = tf.keras.initializers.glorot_uniform(seed=None)\n",
    "        initializer4 = tf.keras.initializers.lecun_normal(seed=None)\n",
    "        initializer5 = tf.keras.initializers.TruncatedNormal(mean=0., stddev=1.)\n",
    "\n",
    "        inp = Input(shape=cqt_input_shape)\n",
    "        img_1 = LeakyReLU(alpha=0.3)(inp)\n",
    "        img_1 = Conv2D(128, kernel_size=(7,7), \n",
    "                       kernel_initializer=initializer4,  \n",
    "                       #trainable = False,\n",
    "                       kernel_regularizer = regularizers.l2(0.001),         \n",
    "                       #use_bias=True, \n",
    "                       #bias_initializer=initializers.Zeros(),\n",
    "                       padding=\"valid\")(img_1)\n",
    "        img_1 = Dropout(0.3)(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = MaxPooling2D()(img_1)\n",
    "        img_1 = Conv2D(128, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, \n",
    "                       #trainable = False,\n",
    "                       kernel_regularizer = regularizers.l2(0.001),            \n",
    "                       #use_bias=True, \n",
    "                       #bias_initializer=initializers.Zeros(),\n",
    "                       padding=\"valid\")(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = MaxPooling2D()(img_1)\n",
    "        img_1 = Dropout(0.3)(img_1)\n",
    "        img_1 = Conv2D(256, kernel_size=(3,3),       \n",
    "                       kernel_initializer=initializer4, \n",
    "                       kernel_regularizer = regularizers.l2(0.001), \n",
    "                       #trainable = False,\n",
    "                       #use_bias=True, \n",
    "                       #bias_initializer=initializers.Zeros(),\n",
    "                       padding=\"valid\")(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.5)(img_1)   \n",
    "        img_1 = Flatten()(img_1)      \n",
    "        img_1 = Dense(512, \n",
    "                      # kernel_initializer=initializer4,  \n",
    "                      kernel_regularizer = regularizers.l2(0.001),\n",
    "                      # trainable = False,\n",
    "                     )(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.5)(img_1)   \n",
    "        \n",
    "        img_1 = Dense(128, kernel_initializer=initializer4, trainable = True,\n",
    "                             kernel_regularizer = regularizers.l2(0.01),\n",
    "                             use_bias=True, \n",
    "                             bias_initializer=initializer4,\n",
    "                            )(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.5)(img_1)   \n",
    "        \n",
    "        img_1 = Dense(32, kernel_initializer=initializer4, trainable = True,\n",
    "                             kernel_regularizer = regularizers.l2(0.01),\n",
    "                             use_bias=True, \n",
    "                             bias_initializer=initializer4,\n",
    "                            )(img_1)\n",
    "        img_1 = LeakyReLU(alpha=0.2)(img_1)\n",
    "        img_1 = Dropout(0.3)(img_1)   \n",
    "\n",
    "\n",
    "        output_layer = Dense(2,activation=activations.sigmoid)(img_1)\n",
    "        model = models.Model(inputs=[inp], outputs=[output_layer])\n",
    "        opt = optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=1e-5, decay=.03, amsgrad=False)\n",
    "        model.compile(optimizer=opt, loss=losses.binary_crossentropy, metrics=['acc'])\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 70, 112, 1)]      0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 70, 112, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 106, 128)      6400      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64, 106, 128)      0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 106, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 51, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 30, 51, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 15, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 13, 23, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 13, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 13, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 76544)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               39191040  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 39,710,050\n",
      "Trainable params: 39,710,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "not_pre_trained = get_model3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 167 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - 11s 63ms/sample - loss: 66054.3904 - acc: 0.5329 - val_loss: 6452.0059 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - 5s 29ms/sample - loss: 48371.1760 - acc: 0.4731 - val_loss: 4949.4604 - val_acc: 0.5000\n",
      "Epoch 3/10\n",
      " 96/167 [================>.............] - ETA: 2s - loss: 37585.7344 - acc: 0.4948"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/api/_v1/keras/losses/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcqt_x_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcqt_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                          class_weight=class_weight)\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    410\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/opt/anaconda3/envs/gansynth/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_not_pretrained = not_pre_trained.fit([cqt_x_train],[to_categorical(cqt_y_train)], \n",
    "                         epochs=10, \n",
    "                         batch_size=96,\n",
    "                         validation_data=([cqt_x_test], to_categorical(cqt_y_test)),\n",
    "                         callbacks=[mcp_save_, reduce_lr],\n",
    "                         class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 16:25:54.101797 140528814368512 hdf5_format.py:258] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model2 = load_model('best_ferry_pretrained_6-7.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing selective layers\n",
    "\n",
    "# sentence_encoder.trainable = True\n",
    "# is_trainable = False\n",
    "# for layer in sentence_encoder.layers:\n",
    "#   if layer.name == 'last layer name':\n",
    "#      is_trainable = True\n",
    "#   if is_trainable:\n",
    "#     layer.trainable = True\n",
    "#   else:\n",
    "#     layer.trainable = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gansynth]",
   "language": "python",
   "name": "conda-env-gansynth-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
